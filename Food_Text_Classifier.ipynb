{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.utils import np_utils\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_dir = 'D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\texts_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = datasets.load_files(text_dir, \n",
    "            description=None, categories=None, load_content=True, shuffle=True, \n",
    "                                        encoding='utf-8', decode_error='strict', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\texts_test_txt\\\\apple_pie\\\\apple_pie_181.txt',\n",
       "       'D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\texts_test_txt\\\\baklava\\\\baklava_636.txt',\n",
       "       'D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\texts_test_txt\\\\apple_pie\\\\apple_pie_573.txt',\n",
       "       'D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\texts_test_txt\\\\apple_pie\\\\apple_pie_493.txt',\n",
       "       'D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\texts_test_txt\\\\apple_pie\\\\apple_pie_203.txt'],\n",
       "      dtype='<U100')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts.filenames[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple_pie', 'baby_back_ribs', 'baklava']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts.target_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 0, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_texts.target[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_train,text_test , y_train, y_test = train_test_split(\n",
    "    all_texts.data, all_texts.target, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF on text data ... \n"
     ]
    }
   ],
   "source": [
    "# Feature Engineering \n",
    "print (\"TF-IDF on text data ... \")\n",
    "tfidf = TfidfVectorizer(binary=True)\n",
    "X_train = tfidf.fit_transform(text_train).astype('float16')\n",
    "X_test = tfidf.transform(text_test).astype('float16')\n",
    "print (\"Done ! \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1765, 57452)\n"
     ]
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "__, num_words = X_train.shape\n",
    "num_classes = len(all_texts.target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create model ... \n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "# Model Training \n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=num_words, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(200, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(160, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(120, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(80, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"Creating model ... \")\n",
    "estimator = KerasClassifier(build_fn=build_model, epochs=50, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compile model ...\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 256)               14707968  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 200)               51400     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 160)               32160     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 120)               19320     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 80)                9680      \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 80)                0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 3)                 243       \n",
      "=================================================================\n",
      "Total params: 14,820,771\n",
      "Trainable params: 14,820,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "1765/1765 [==============================] - 7s 4ms/step - loss: 1.0832 - acc: 0.3836\n",
      "Epoch 2/15\n",
      "1765/1765 [==============================] - 5s 3ms/step - loss: 0.8251 - acc: 0.6198\n",
      "Epoch 3/15\n",
      "1765/1765 [==============================] - 5s 3ms/step - loss: 0.2734 - acc: 0.9105\n",
      "Epoch 4/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0622 - acc: 0.9768\n",
      "Epoch 5/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0398 - acc: 0.9892\n",
      "Epoch 6/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0281 - acc: 0.9898\n",
      "Epoch 7/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0292 - acc: 0.9898\n",
      "Epoch 8/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0206 - acc: 0.9926\n",
      "Epoch 9/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0235 - acc: 0.9892\n",
      "Epoch 10/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0299 - acc: 0.9904\n",
      "Epoch 11/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0164 - acc: 0.9938\n",
      "Epoch 12/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0155 - acc: 0.9938\n",
      "Epoch 13/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0199 - acc: 0.9915\n",
      "Epoch 14/15\n",
      "1765/1765 [==============================] - 5s 3ms/step - loss: 0.0193 - acc: 0.9904\n",
      "Epoch 15/15\n",
      "1765/1765 [==============================] - 6s 3ms/step - loss: 0.0168 - acc: 0.9892\n",
      "Completed !\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "estimator.fit(X_train, y_train)\n",
    "print(\"Completed !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on test data ... \n",
      "Accuracy :  0.9471264367816092\n"
     ]
    }
   ],
   "source": [
    "# Predictions \n",
    "print (\"Predict on test data ... \")\n",
    "y_pred = estimator.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most informative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
       "     verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict on test data ... \n",
      "Accuracy :  0.967816091954023\n"
     ]
    }
   ],
   "source": [
    "print (\"Predict on test data ... \")\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top10(vectorizer, clf, class_labels):\n",
    "    \"\"\"\n",
    "    Prints features with the highest coefficient values, per class \\n\n",
    "    https://stackoverflow.com/questions/11116697/how-to-get-most-informative-features-for-scikit-learn-classifiers\n",
    "    \"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (class_label,\n",
    "              \", \".join(feature_names[j] for j in top10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple_pie: caramel, cinnamon, filling, peeled, pies, flour, crust, pie, apples, apple\n",
      "baby_back_ribs: pepper, tender, rib, pork, barbecue, bbq, grill, back, baby, ribs\n",
      "baklava: filo, syrup, pistachios, pistachio, greek, sheets, walnuts, nuts, phyllo, baklava\n"
     ]
    }
   ],
   "source": [
    "print_top10(tfidf, clf, all_texts.target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
