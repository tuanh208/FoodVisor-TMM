{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import torch.nn as nn\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "import bcolz\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import utils; imp.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu =  False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = 'D:\\\\Tu Beo\\\\Education\\\\FoodVisor\\\\data\\\\UPMC_Food101\\\\images'\n",
    "data_dir = '/home/foodlovers/FoodVisor/data/images'\n",
    "# data_dir = \"/home/foodlovers/FoodVisor/FoodVisor-TMM/data/UPMC_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), prep2)\n",
    "         for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dsets['train'].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsets['train'].class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dsets['train'].imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 67988, 'test': 22716}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset_sizes = {x: len(dsets[x]) for x in ['train', 'test']}\n",
    "dset_sizes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=32,\n",
    "                                               shuffle=shuffle_valtrain(x), num_workers=6)\n",
    "                for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = torch.utils.data.DataLoader(dsets['test'], batch_size=5, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for data in dataset_valid:\n",
    "    if count == 0:\n",
    "        inputs_try,labels_try = data\n",
    "    else:\n",
    "        break\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_try.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs_try)\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in labels_try])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of training data\n",
    "inputs, classes = next(iter(dset_loaders['train']))\n",
    "\n",
    "n_images = 8\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a batch of validation data\n",
    "inputs, classes = next(iter(dset_loaders['test']))\n",
    "\n",
    "n_images = 8\n",
    "\n",
    "# Make a grid from batch\n",
    "out = torchvision.utils.make_grid(inputs[0:n_images])\n",
    "\n",
    "imshow(out, title=[dset_classes[x] for x in classes[0:n_images]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating InceptionV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception = models.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    model_inception = model_inception.cuda()\n",
    "    \n",
    "inputs_try , labels_try = var_cgpu(inputs_try,use_gpu),var_cgpu(labels_try,use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try,__ = model_inception(inputs_try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_try.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs_try.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the last layer and setting the gradient false to all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(model_inception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_inception.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception.fc = nn.Linear(2048, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inception.AuxLogits.fc = nn.Linear(768, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_inception.fc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    model_inception = model_inception.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating pre-calculated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat(dataset):\n",
    "    conv_features = []\n",
    "    labels_list = []\n",
    "    count = 0\n",
    "    for data in dataset:\n",
    "        print(count)\n",
    "        count += 1\n",
    "        inputs,labels = data\n",
    "        \n",
    "        #x = model_vgg.features(inputs)\n",
    "        conv_features.extend(inputs)\n",
    "        labels_list.extend(labels)\n",
    "        if count == 10 :\n",
    "            break\n",
    "    #conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "conv_feat_train,labels_train = preconvfeat(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_train[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_array(data_dir+'/vgg16/conv_feat_train.bc',conv_feat_train)\n",
    "save_array(data_dir+'/vgg16/labels_train.bc',labels_train)\n",
    "save_array(data_dir+'/vgg16/conv_feat_val.bc',conv_feat_val)\n",
    "save_array(data_dir+'/vgg16/labels_val.bc',labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_train = load_array(data_dir+'\\\\vgg16\\\\conv_feat_train.bc')\n",
    "labels_train = load_array(data_dir+'\\\\vgg16\\\\labels_train.bc')\n",
    "conv_feat_val = load_array(data_dir+'\\\\vgg16\\\\conv_feat_val.bc')\n",
    "labels_val = load_array(data_dir+'\\\\vgg16\\\\labels_val.bc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training fully connected module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer_incep = torch.optim.SGD(model_inception.parameters(),lr = lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(conv_feat,labels,batch_size=64,shuffle=True):\n",
    "    labels = np.array(labels)\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(len(conv_feat))\n",
    "        conv_feat = conv_feat[index]\n",
    "        labels = labels[index]\n",
    "    for idx in range(0,len(conv_feat),batch_size):\n",
    "        yield(conv_feat[idx:idx+batch_size],labels[idx:idx+batch_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs = 1,train = True, validate = False) :\n",
    "    for epoch in range(epochs) :\n",
    "        if train == True :\n",
    "            #=========================TRAINING=================================#\n",
    "            start_time_epoch = time.time()\n",
    "            \n",
    "            model_inception.train()\n",
    "            \n",
    "            loss_history = []\n",
    "            acc_history = []\n",
    "    \n",
    "            print(\"Epoch:\", epoch,\"/\",epochs,\"===============================================\")\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "\n",
    "\n",
    "            for i, data in enumerate(dset_loaders['train'], 0):\n",
    "                start_time = time.time()\n",
    "\n",
    "                # get the inputs\n",
    "                inputs, classes = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs , classes = inputs.cuda(), classes.cuda()\n",
    "\n",
    "                # calulate outputs and losses\n",
    "                outputs, aux_outputs = model_inception(inputs)\n",
    "                loss = criterion(outputs,classes) + 0.4*criterion(aux_outputs,classes)         \n",
    "\n",
    "                # autograd\n",
    "                optimizer_incep.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer_incep.step()\n",
    "\n",
    "                # statistics\n",
    "                batch_loss = loss.data.item()\n",
    "                _,preds = torch.max(outputs.data,1)\n",
    "                batch_corrects = torch.sum(preds == classes.data)\n",
    "                running_loss += batch_loss\n",
    "                running_corrects += batch_corrects\n",
    "\n",
    "                print('Batch {:d}/{:d} - Loss: {:.4f} Acc: {:.4f} - Time : {:.2f}s'.format(i+1,len(dset_loaders['train']),\n",
    "                             batch_loss/len(classes), float(batch_corrects)/len(classes), time.time() - start_time), end=\"\\r\")\n",
    "\n",
    "            epoch_loss = running_loss / dset_sizes['train']\n",
    "            epoch_acc = running_corrects.data.item() / dset_sizes['train']\n",
    "            \n",
    "            loss_history.append(epoch_loss)\n",
    "            acc_history.append(epoch_acc)\n",
    "            \n",
    "            print('Epoch {:d} completed in {:.2f} seconds ! Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch, time.time() - start_time_epoch, epoch_loss, epoch_acc))\n",
    "            \n",
    "        if validate == True :\n",
    "            #=========================VALIDATING=================================#\n",
    "            \n",
    "            model_inception.eval()\n",
    "            \n",
    "            if train == True :\n",
    "                val_loss_history = []\n",
    "                val_acc_history = []\n",
    "            \n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0.0\n",
    "            \n",
    "            total = 0\n",
    "\n",
    "            for i, data in enumerate(dset_loaders['test'], 0):\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # get the inputs\n",
    "                inputs, classes = data\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs , classes = inputs.cuda(), classes.cuda()\n",
    "\n",
    "                outputs = model_inception(inputs)\n",
    "\n",
    "                loss = criterion(outputs,classes)        \n",
    "\n",
    "                _,preds = torch.max(outputs.data,1)\n",
    "\n",
    "                # statistics\n",
    "\n",
    "                val_loss += loss.data.item()\n",
    "                val_corrects += torch.sum(preds == classes.data)\n",
    "                total += classes.size(0)\n",
    "                \n",
    "                print('Validating batch {:d}/{:d} - {:.2f}s ...'.format(i+1,len(dset_loaders['test'])\n",
    "                                                                , time.time() - start_time), end=\"\\r\")\n",
    "\n",
    "            val_epoch_loss = val_loss / dset_sizes['test']\n",
    "            val_epoch_acc = val_corrects.data.item() / dset_sizes['test']\n",
    "\n",
    "            print('Val Loss: {:.4f} Val Acc: {:.4f}'.format(\n",
    "                             val_epoch_loss,val_epoch_acc))\n",
    "            \n",
    "            if train == False :\n",
    "                return\n",
    "            else :\n",
    "                val_loss_history.append(val_epoch_loss)\n",
    "                val_acc_history.append(val_epoch_acc)\n",
    "    \n",
    "    if train == False :\n",
    "        return 'On fait rien!'\n",
    "    elif validate == False :\n",
    "        return loss_history, acc_history\n",
    "    else :\n",
    "        return loss_history, acc_history,val_loss_history,val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 15 ===============================================\n",
      "Batch 1010/2125 - Loss: 0.1126 Acc: 0.3438 - Time : 1.18s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed in 2521.16 seconds ! Loss: 0.1224 Acc: 0.3394\n",
      "Val Loss: 0.0732 Val Acc: 0.4549 ...\n",
      "Epoch: 1 / 15 ===============================================\n",
      "Batch 708/2125 - Loss: 0.0793 Acc: 0.5938 - Time : 1.18s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed in 2526.47 seconds ! Loss: 0.0915 Acc: 0.4945\n",
      "Val Loss: 0.0719 Val Acc: 0.4576 ...\n",
      "Epoch: 2 / 15 ===============================================\n",
      "Batch 1440/2125 - Loss: 0.0826 Acc: 0.5625 - Time : 1.19s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 completed in 2526.48 seconds ! Loss: 0.0763 Acc: 0.5691\n",
      "Val Loss: 0.0628 Val Acc: 0.5349 ...\n",
      "Epoch: 3 / 15 ===============================================\n",
      "Batch 1839/2125 - Loss: 0.0703 Acc: 0.5938 - Time : 1.19s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 completed in 2526.31 seconds ! Loss: 0.0648 Acc: 0.6249\n",
      "Val Loss: 0.0639 Val Acc: 0.5314 ...\n",
      "Epoch: 4 / 15 ===============================================\n",
      "Batch 1428/2125 - Loss: 0.0780 Acc: 0.5312 - Time : 1.19s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 completed in 2522.59 seconds ! Loss: 0.0549 Acc: 0.6760\n",
      "Val Loss: 0.0619 Val Acc: 0.5581 ...\n",
      "Epoch: 5 / 15 ===============================================\n",
      "Batch 492/2125 - Loss: 0.0310 Acc: 0.7188 - Time : 1.17s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 completed in 2502.38 seconds ! Loss: 0.0466 Acc: 0.7152\n",
      "Val Loss: 0.0638 Val Acc: 0.5561 ...\n",
      "Epoch: 6 / 15 ===============================================\n",
      "Batch 755/2125 - Loss: 0.0527 Acc: 0.6562 - Time : 1.18s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 completed in 2504.02 seconds ! Loss: 0.0392 Acc: 0.7521\n",
      "Val Loss: 0.0651 Val Acc: 0.5637 ...\n",
      "Epoch: 7 / 15 ===============================================\n",
      "Batch 857/2125 - Loss: 0.0487 Acc: 0.7188 - Time : 1.17s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 completed in 2502.24 seconds ! Loss: 0.0333 Acc: 0.7811\n",
      "Val Loss: 0.0664 Val Acc: 0.5573 ...\n",
      "Epoch: 8 / 15 ===============================================\n",
      "Batch 1944/2125 - Loss: 0.0249 Acc: 0.8750 - Time : 1.17s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 completed in 2501.00 seconds ! Loss: 0.0274 Acc: 0.8165\n",
      "Val Loss: 0.0711 Val Acc: 0.5578 ...\n",
      "Epoch: 9 / 15 ===============================================\n",
      "Batch 50/2125 - Loss: 0.0033 Acc: 1.0000 - Time : 1.18s\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 218/2125 - Loss: 0.0105 Acc: 0.9062 - Time : 1.17s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-d6a952bdb2d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-a7eeb3557abe>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(epochs, train, validate)\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0moptimizer_incep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                 \u001b[0moptimizer_incep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/optim/sgd.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     99\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'momentum_buffer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m                         \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdampening\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mnesterov\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m                         \u001b[0md_p\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(train=True,validate=True,epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "Conv2d_1a_3x3.conv.weight \t torch.Size([32, 3, 3, 3])\n",
      "Conv2d_1a_3x3.bn.weight \t torch.Size([32])\n",
      "Conv2d_1a_3x3.bn.bias \t torch.Size([32])\n",
      "Conv2d_1a_3x3.bn.running_mean \t torch.Size([32])\n",
      "Conv2d_1a_3x3.bn.running_var \t torch.Size([32])\n",
      "Conv2d_1a_3x3.bn.num_batches_tracked \t torch.Size([])\n",
      "Conv2d_2a_3x3.conv.weight \t torch.Size([32, 32, 3, 3])\n",
      "Conv2d_2a_3x3.bn.weight \t torch.Size([32])\n",
      "Conv2d_2a_3x3.bn.bias \t torch.Size([32])\n",
      "Conv2d_2a_3x3.bn.running_mean \t torch.Size([32])\n",
      "Conv2d_2a_3x3.bn.running_var \t torch.Size([32])\n",
      "Conv2d_2a_3x3.bn.num_batches_tracked \t torch.Size([])\n",
      "Conv2d_2b_3x3.conv.weight \t torch.Size([64, 32, 3, 3])\n",
      "Conv2d_2b_3x3.bn.weight \t torch.Size([64])\n",
      "Conv2d_2b_3x3.bn.bias \t torch.Size([64])\n",
      "Conv2d_2b_3x3.bn.running_mean \t torch.Size([64])\n",
      "Conv2d_2b_3x3.bn.running_var \t torch.Size([64])\n",
      "Conv2d_2b_3x3.bn.num_batches_tracked \t torch.Size([])\n",
      "Conv2d_3b_1x1.conv.weight \t torch.Size([80, 64, 1, 1])\n",
      "Conv2d_3b_1x1.bn.weight \t torch.Size([80])\n",
      "Conv2d_3b_1x1.bn.bias \t torch.Size([80])\n",
      "Conv2d_3b_1x1.bn.running_mean \t torch.Size([80])\n",
      "Conv2d_3b_1x1.bn.running_var \t torch.Size([80])\n",
      "Conv2d_3b_1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Conv2d_4a_3x3.conv.weight \t torch.Size([192, 80, 3, 3])\n",
      "Conv2d_4a_3x3.bn.weight \t torch.Size([192])\n",
      "Conv2d_4a_3x3.bn.bias \t torch.Size([192])\n",
      "Conv2d_4a_3x3.bn.running_mean \t torch.Size([192])\n",
      "Conv2d_4a_3x3.bn.running_var \t torch.Size([192])\n",
      "Conv2d_4a_3x3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch1x1.conv.weight \t torch.Size([64, 192, 1, 1])\n",
      "Mixed_5b.branch1x1.bn.weight \t torch.Size([64])\n",
      "Mixed_5b.branch1x1.bn.bias \t torch.Size([64])\n",
      "Mixed_5b.branch1x1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5b.branch1x1.bn.running_var \t torch.Size([64])\n",
      "Mixed_5b.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch5x5_1.conv.weight \t torch.Size([48, 192, 1, 1])\n",
      "Mixed_5b.branch5x5_1.bn.weight \t torch.Size([48])\n",
      "Mixed_5b.branch5x5_1.bn.bias \t torch.Size([48])\n",
      "Mixed_5b.branch5x5_1.bn.running_mean \t torch.Size([48])\n",
      "Mixed_5b.branch5x5_1.bn.running_var \t torch.Size([48])\n",
      "Mixed_5b.branch5x5_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch5x5_2.conv.weight \t torch.Size([64, 48, 5, 5])\n",
      "Mixed_5b.branch5x5_2.bn.weight \t torch.Size([64])\n",
      "Mixed_5b.branch5x5_2.bn.bias \t torch.Size([64])\n",
      "Mixed_5b.branch5x5_2.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5b.branch5x5_2.bn.running_var \t torch.Size([64])\n",
      "Mixed_5b.branch5x5_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch3x3dbl_1.conv.weight \t torch.Size([64, 192, 1, 1])\n",
      "Mixed_5b.branch3x3dbl_1.bn.weight \t torch.Size([64])\n",
      "Mixed_5b.branch3x3dbl_1.bn.bias \t torch.Size([64])\n",
      "Mixed_5b.branch3x3dbl_1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5b.branch3x3dbl_1.bn.running_var \t torch.Size([64])\n",
      "Mixed_5b.branch3x3dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch3x3dbl_2.conv.weight \t torch.Size([96, 64, 3, 3])\n",
      "Mixed_5b.branch3x3dbl_2.bn.weight \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_2.bn.bias \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_2.bn.running_mean \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_2.bn.running_var \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch3x3dbl_3.conv.weight \t torch.Size([96, 96, 3, 3])\n",
      "Mixed_5b.branch3x3dbl_3.bn.weight \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_3.bn.bias \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_3.bn.running_mean \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_3.bn.running_var \t torch.Size([96])\n",
      "Mixed_5b.branch3x3dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5b.branch_pool.conv.weight \t torch.Size([32, 192, 1, 1])\n",
      "Mixed_5b.branch_pool.bn.weight \t torch.Size([32])\n",
      "Mixed_5b.branch_pool.bn.bias \t torch.Size([32])\n",
      "Mixed_5b.branch_pool.bn.running_mean \t torch.Size([32])\n",
      "Mixed_5b.branch_pool.bn.running_var \t torch.Size([32])\n",
      "Mixed_5b.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch1x1.conv.weight \t torch.Size([64, 256, 1, 1])\n",
      "Mixed_5c.branch1x1.bn.weight \t torch.Size([64])\n",
      "Mixed_5c.branch1x1.bn.bias \t torch.Size([64])\n",
      "Mixed_5c.branch1x1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5c.branch1x1.bn.running_var \t torch.Size([64])\n",
      "Mixed_5c.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch5x5_1.conv.weight \t torch.Size([48, 256, 1, 1])\n",
      "Mixed_5c.branch5x5_1.bn.weight \t torch.Size([48])\n",
      "Mixed_5c.branch5x5_1.bn.bias \t torch.Size([48])\n",
      "Mixed_5c.branch5x5_1.bn.running_mean \t torch.Size([48])\n",
      "Mixed_5c.branch5x5_1.bn.running_var \t torch.Size([48])\n",
      "Mixed_5c.branch5x5_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch5x5_2.conv.weight \t torch.Size([64, 48, 5, 5])\n",
      "Mixed_5c.branch5x5_2.bn.weight \t torch.Size([64])\n",
      "Mixed_5c.branch5x5_2.bn.bias \t torch.Size([64])\n",
      "Mixed_5c.branch5x5_2.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5c.branch5x5_2.bn.running_var \t torch.Size([64])\n",
      "Mixed_5c.branch5x5_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch3x3dbl_1.conv.weight \t torch.Size([64, 256, 1, 1])\n",
      "Mixed_5c.branch3x3dbl_1.bn.weight \t torch.Size([64])\n",
      "Mixed_5c.branch3x3dbl_1.bn.bias \t torch.Size([64])\n",
      "Mixed_5c.branch3x3dbl_1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5c.branch3x3dbl_1.bn.running_var \t torch.Size([64])\n",
      "Mixed_5c.branch3x3dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch3x3dbl_2.conv.weight \t torch.Size([96, 64, 3, 3])\n",
      "Mixed_5c.branch3x3dbl_2.bn.weight \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_2.bn.bias \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_2.bn.running_mean \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_2.bn.running_var \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch3x3dbl_3.conv.weight \t torch.Size([96, 96, 3, 3])\n",
      "Mixed_5c.branch3x3dbl_3.bn.weight \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_3.bn.bias \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_3.bn.running_mean \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_3.bn.running_var \t torch.Size([96])\n",
      "Mixed_5c.branch3x3dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5c.branch_pool.conv.weight \t torch.Size([64, 256, 1, 1])\n",
      "Mixed_5c.branch_pool.bn.weight \t torch.Size([64])\n",
      "Mixed_5c.branch_pool.bn.bias \t torch.Size([64])\n",
      "Mixed_5c.branch_pool.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5c.branch_pool.bn.running_var \t torch.Size([64])\n",
      "Mixed_5c.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch1x1.conv.weight \t torch.Size([64, 288, 1, 1])\n",
      "Mixed_5d.branch1x1.bn.weight \t torch.Size([64])\n",
      "Mixed_5d.branch1x1.bn.bias \t torch.Size([64])\n",
      "Mixed_5d.branch1x1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5d.branch1x1.bn.running_var \t torch.Size([64])\n",
      "Mixed_5d.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch5x5_1.conv.weight \t torch.Size([48, 288, 1, 1])\n",
      "Mixed_5d.branch5x5_1.bn.weight \t torch.Size([48])\n",
      "Mixed_5d.branch5x5_1.bn.bias \t torch.Size([48])\n",
      "Mixed_5d.branch5x5_1.bn.running_mean \t torch.Size([48])\n",
      "Mixed_5d.branch5x5_1.bn.running_var \t torch.Size([48])\n",
      "Mixed_5d.branch5x5_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch5x5_2.conv.weight \t torch.Size([64, 48, 5, 5])\n",
      "Mixed_5d.branch5x5_2.bn.weight \t torch.Size([64])\n",
      "Mixed_5d.branch5x5_2.bn.bias \t torch.Size([64])\n",
      "Mixed_5d.branch5x5_2.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5d.branch5x5_2.bn.running_var \t torch.Size([64])\n",
      "Mixed_5d.branch5x5_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch3x3dbl_1.conv.weight \t torch.Size([64, 288, 1, 1])\n",
      "Mixed_5d.branch3x3dbl_1.bn.weight \t torch.Size([64])\n",
      "Mixed_5d.branch3x3dbl_1.bn.bias \t torch.Size([64])\n",
      "Mixed_5d.branch3x3dbl_1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5d.branch3x3dbl_1.bn.running_var \t torch.Size([64])\n",
      "Mixed_5d.branch3x3dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch3x3dbl_2.conv.weight \t torch.Size([96, 64, 3, 3])\n",
      "Mixed_5d.branch3x3dbl_2.bn.weight \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_2.bn.bias \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_2.bn.running_mean \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_2.bn.running_var \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch3x3dbl_3.conv.weight \t torch.Size([96, 96, 3, 3])\n",
      "Mixed_5d.branch3x3dbl_3.bn.weight \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_3.bn.bias \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_3.bn.running_mean \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_3.bn.running_var \t torch.Size([96])\n",
      "Mixed_5d.branch3x3dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_5d.branch_pool.conv.weight \t torch.Size([64, 288, 1, 1])\n",
      "Mixed_5d.branch_pool.bn.weight \t torch.Size([64])\n",
      "Mixed_5d.branch_pool.bn.bias \t torch.Size([64])\n",
      "Mixed_5d.branch_pool.bn.running_mean \t torch.Size([64])\n",
      "Mixed_5d.branch_pool.bn.running_var \t torch.Size([64])\n",
      "Mixed_5d.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6a.branch3x3.conv.weight \t torch.Size([384, 288, 3, 3])\n",
      "Mixed_6a.branch3x3.bn.weight \t torch.Size([384])\n",
      "Mixed_6a.branch3x3.bn.bias \t torch.Size([384])\n",
      "Mixed_6a.branch3x3.bn.running_mean \t torch.Size([384])\n",
      "Mixed_6a.branch3x3.bn.running_var \t torch.Size([384])\n",
      "Mixed_6a.branch3x3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6a.branch3x3dbl_1.conv.weight \t torch.Size([64, 288, 1, 1])\n",
      "Mixed_6a.branch3x3dbl_1.bn.weight \t torch.Size([64])\n",
      "Mixed_6a.branch3x3dbl_1.bn.bias \t torch.Size([64])\n",
      "Mixed_6a.branch3x3dbl_1.bn.running_mean \t torch.Size([64])\n",
      "Mixed_6a.branch3x3dbl_1.bn.running_var \t torch.Size([64])\n",
      "Mixed_6a.branch3x3dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6a.branch3x3dbl_2.conv.weight \t torch.Size([96, 64, 3, 3])\n",
      "Mixed_6a.branch3x3dbl_2.bn.weight \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_2.bn.bias \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_2.bn.running_mean \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_2.bn.running_var \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6a.branch3x3dbl_3.conv.weight \t torch.Size([96, 96, 3, 3])\n",
      "Mixed_6a.branch3x3dbl_3.bn.weight \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_3.bn.bias \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_3.bn.running_mean \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_3.bn.running_var \t torch.Size([96])\n",
      "Mixed_6a.branch3x3dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch1x1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6b.branch1x1.bn.weight \t torch.Size([192])\n",
      "Mixed_6b.branch1x1.bn.bias \t torch.Size([192])\n",
      "Mixed_6b.branch1x1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6b.branch1x1.bn.running_var \t torch.Size([192])\n",
      "Mixed_6b.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7_1.conv.weight \t torch.Size([128, 768, 1, 1])\n",
      "Mixed_6b.branch7x7_1.bn.weight \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_1.bn.bias \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_1.bn.running_mean \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_1.bn.running_var \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7_2.conv.weight \t torch.Size([128, 128, 1, 7])\n",
      "Mixed_6b.branch7x7_2.bn.weight \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_2.bn.bias \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_2.bn.running_mean \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_2.bn.running_var \t torch.Size([128])\n",
      "Mixed_6b.branch7x7_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7_3.conv.weight \t torch.Size([192, 128, 7, 1])\n",
      "Mixed_6b.branch7x7_3.bn.weight \t torch.Size([192])\n",
      "Mixed_6b.branch7x7_3.bn.bias \t torch.Size([192])\n",
      "Mixed_6b.branch7x7_3.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6b.branch7x7_3.bn.running_var \t torch.Size([192])\n",
      "Mixed_6b.branch7x7_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7dbl_1.conv.weight \t torch.Size([128, 768, 1, 1])\n",
      "Mixed_6b.branch7x7dbl_1.bn.weight \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_1.bn.bias \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_1.bn.running_mean \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_1.bn.running_var \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7dbl_2.conv.weight \t torch.Size([128, 128, 7, 1])\n",
      "Mixed_6b.branch7x7dbl_2.bn.weight \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_2.bn.bias \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_2.bn.running_mean \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_2.bn.running_var \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7dbl_3.conv.weight \t torch.Size([128, 128, 1, 7])\n",
      "Mixed_6b.branch7x7dbl_3.bn.weight \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_3.bn.bias \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_3.bn.running_mean \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_3.bn.running_var \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7dbl_4.conv.weight \t torch.Size([128, 128, 7, 1])\n",
      "Mixed_6b.branch7x7dbl_4.bn.weight \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_4.bn.bias \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_4.bn.running_mean \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_4.bn.running_var \t torch.Size([128])\n",
      "Mixed_6b.branch7x7dbl_4.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch7x7dbl_5.conv.weight \t torch.Size([192, 128, 1, 7])\n",
      "Mixed_6b.branch7x7dbl_5.bn.weight \t torch.Size([192])\n",
      "Mixed_6b.branch7x7dbl_5.bn.bias \t torch.Size([192])\n",
      "Mixed_6b.branch7x7dbl_5.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6b.branch7x7dbl_5.bn.running_var \t torch.Size([192])\n",
      "Mixed_6b.branch7x7dbl_5.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6b.branch_pool.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6b.branch_pool.bn.weight \t torch.Size([192])\n",
      "Mixed_6b.branch_pool.bn.bias \t torch.Size([192])\n",
      "Mixed_6b.branch_pool.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6b.branch_pool.bn.running_var \t torch.Size([192])\n",
      "Mixed_6b.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch1x1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6c.branch1x1.bn.weight \t torch.Size([192])\n",
      "Mixed_6c.branch1x1.bn.bias \t torch.Size([192])\n",
      "Mixed_6c.branch1x1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6c.branch1x1.bn.running_var \t torch.Size([192])\n",
      "Mixed_6c.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7_1.conv.weight \t torch.Size([160, 768, 1, 1])\n",
      "Mixed_6c.branch7x7_1.bn.weight \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_1.bn.bias \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_1.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_1.bn.running_var \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7_2.conv.weight \t torch.Size([160, 160, 1, 7])\n",
      "Mixed_6c.branch7x7_2.bn.weight \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_2.bn.bias \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_2.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_2.bn.running_var \t torch.Size([160])\n",
      "Mixed_6c.branch7x7_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7_3.conv.weight \t torch.Size([192, 160, 7, 1])\n",
      "Mixed_6c.branch7x7_3.bn.weight \t torch.Size([192])\n",
      "Mixed_6c.branch7x7_3.bn.bias \t torch.Size([192])\n",
      "Mixed_6c.branch7x7_3.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6c.branch7x7_3.bn.running_var \t torch.Size([192])\n",
      "Mixed_6c.branch7x7_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7dbl_1.conv.weight \t torch.Size([160, 768, 1, 1])\n",
      "Mixed_6c.branch7x7dbl_1.bn.weight \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_1.bn.bias \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_1.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_1.bn.running_var \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7dbl_2.conv.weight \t torch.Size([160, 160, 7, 1])\n",
      "Mixed_6c.branch7x7dbl_2.bn.weight \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_2.bn.bias \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_2.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_2.bn.running_var \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7dbl_3.conv.weight \t torch.Size([160, 160, 1, 7])\n",
      "Mixed_6c.branch7x7dbl_3.bn.weight \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_3.bn.bias \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_3.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_3.bn.running_var \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7dbl_4.conv.weight \t torch.Size([160, 160, 7, 1])\n",
      "Mixed_6c.branch7x7dbl_4.bn.weight \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_4.bn.bias \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_4.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_4.bn.running_var \t torch.Size([160])\n",
      "Mixed_6c.branch7x7dbl_4.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch7x7dbl_5.conv.weight \t torch.Size([192, 160, 1, 7])\n",
      "Mixed_6c.branch7x7dbl_5.bn.weight \t torch.Size([192])\n",
      "Mixed_6c.branch7x7dbl_5.bn.bias \t torch.Size([192])\n",
      "Mixed_6c.branch7x7dbl_5.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6c.branch7x7dbl_5.bn.running_var \t torch.Size([192])\n",
      "Mixed_6c.branch7x7dbl_5.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6c.branch_pool.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6c.branch_pool.bn.weight \t torch.Size([192])\n",
      "Mixed_6c.branch_pool.bn.bias \t torch.Size([192])\n",
      "Mixed_6c.branch_pool.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6c.branch_pool.bn.running_var \t torch.Size([192])\n",
      "Mixed_6c.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch1x1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6d.branch1x1.bn.weight \t torch.Size([192])\n",
      "Mixed_6d.branch1x1.bn.bias \t torch.Size([192])\n",
      "Mixed_6d.branch1x1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6d.branch1x1.bn.running_var \t torch.Size([192])\n",
      "Mixed_6d.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7_1.conv.weight \t torch.Size([160, 768, 1, 1])\n",
      "Mixed_6d.branch7x7_1.bn.weight \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_1.bn.bias \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_1.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_1.bn.running_var \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7_2.conv.weight \t torch.Size([160, 160, 1, 7])\n",
      "Mixed_6d.branch7x7_2.bn.weight \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_2.bn.bias \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_2.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_2.bn.running_var \t torch.Size([160])\n",
      "Mixed_6d.branch7x7_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7_3.conv.weight \t torch.Size([192, 160, 7, 1])\n",
      "Mixed_6d.branch7x7_3.bn.weight \t torch.Size([192])\n",
      "Mixed_6d.branch7x7_3.bn.bias \t torch.Size([192])\n",
      "Mixed_6d.branch7x7_3.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6d.branch7x7_3.bn.running_var \t torch.Size([192])\n",
      "Mixed_6d.branch7x7_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7dbl_1.conv.weight \t torch.Size([160, 768, 1, 1])\n",
      "Mixed_6d.branch7x7dbl_1.bn.weight \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_1.bn.bias \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_1.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_1.bn.running_var \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7dbl_2.conv.weight \t torch.Size([160, 160, 7, 1])\n",
      "Mixed_6d.branch7x7dbl_2.bn.weight \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_2.bn.bias \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_2.bn.running_mean \t torch.Size([160])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed_6d.branch7x7dbl_2.bn.running_var \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7dbl_3.conv.weight \t torch.Size([160, 160, 1, 7])\n",
      "Mixed_6d.branch7x7dbl_3.bn.weight \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_3.bn.bias \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_3.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_3.bn.running_var \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7dbl_4.conv.weight \t torch.Size([160, 160, 7, 1])\n",
      "Mixed_6d.branch7x7dbl_4.bn.weight \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_4.bn.bias \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_4.bn.running_mean \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_4.bn.running_var \t torch.Size([160])\n",
      "Mixed_6d.branch7x7dbl_4.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch7x7dbl_5.conv.weight \t torch.Size([192, 160, 1, 7])\n",
      "Mixed_6d.branch7x7dbl_5.bn.weight \t torch.Size([192])\n",
      "Mixed_6d.branch7x7dbl_5.bn.bias \t torch.Size([192])\n",
      "Mixed_6d.branch7x7dbl_5.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6d.branch7x7dbl_5.bn.running_var \t torch.Size([192])\n",
      "Mixed_6d.branch7x7dbl_5.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6d.branch_pool.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6d.branch_pool.bn.weight \t torch.Size([192])\n",
      "Mixed_6d.branch_pool.bn.bias \t torch.Size([192])\n",
      "Mixed_6d.branch_pool.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6d.branch_pool.bn.running_var \t torch.Size([192])\n",
      "Mixed_6d.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch1x1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6e.branch1x1.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch1x1.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch1x1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch1x1.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7_1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6e.branch7x7_1.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_1.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_1.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7_2.conv.weight \t torch.Size([192, 192, 1, 7])\n",
      "Mixed_6e.branch7x7_2.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_2.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_2.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_2.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7_3.conv.weight \t torch.Size([192, 192, 7, 1])\n",
      "Mixed_6e.branch7x7_3.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_3.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_3.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_3.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7dbl_1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6e.branch7x7dbl_1.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_1.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_1.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7dbl_2.conv.weight \t torch.Size([192, 192, 7, 1])\n",
      "Mixed_6e.branch7x7dbl_2.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_2.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_2.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_2.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7dbl_3.conv.weight \t torch.Size([192, 192, 1, 7])\n",
      "Mixed_6e.branch7x7dbl_3.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_3.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_3.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_3.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7dbl_4.conv.weight \t torch.Size([192, 192, 7, 1])\n",
      "Mixed_6e.branch7x7dbl_4.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_4.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_4.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_4.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_4.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch7x7dbl_5.conv.weight \t torch.Size([192, 192, 1, 7])\n",
      "Mixed_6e.branch7x7dbl_5.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_5.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_5.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_5.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch7x7dbl_5.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_6e.branch_pool.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_6e.branch_pool.bn.weight \t torch.Size([192])\n",
      "Mixed_6e.branch_pool.bn.bias \t torch.Size([192])\n",
      "Mixed_6e.branch_pool.bn.running_mean \t torch.Size([192])\n",
      "Mixed_6e.branch_pool.bn.running_var \t torch.Size([192])\n",
      "Mixed_6e.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "AuxLogits.conv0.conv.weight \t torch.Size([128, 768, 1, 1])\n",
      "AuxLogits.conv0.bn.weight \t torch.Size([128])\n",
      "AuxLogits.conv0.bn.bias \t torch.Size([128])\n",
      "AuxLogits.conv0.bn.running_mean \t torch.Size([128])\n",
      "AuxLogits.conv0.bn.running_var \t torch.Size([128])\n",
      "AuxLogits.conv0.bn.num_batches_tracked \t torch.Size([])\n",
      "AuxLogits.conv1.conv.weight \t torch.Size([768, 128, 5, 5])\n",
      "AuxLogits.conv1.bn.weight \t torch.Size([768])\n",
      "AuxLogits.conv1.bn.bias \t torch.Size([768])\n",
      "AuxLogits.conv1.bn.running_mean \t torch.Size([768])\n",
      "AuxLogits.conv1.bn.running_var \t torch.Size([768])\n",
      "AuxLogits.conv1.bn.num_batches_tracked \t torch.Size([])\n",
      "AuxLogits.fc.weight \t torch.Size([101, 768])\n",
      "AuxLogits.fc.bias \t torch.Size([101])\n",
      "Mixed_7a.branch3x3_1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_7a.branch3x3_1.bn.weight \t torch.Size([192])\n",
      "Mixed_7a.branch3x3_1.bn.bias \t torch.Size([192])\n",
      "Mixed_7a.branch3x3_1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7a.branch3x3_1.bn.running_var \t torch.Size([192])\n",
      "Mixed_7a.branch3x3_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7a.branch3x3_2.conv.weight \t torch.Size([320, 192, 3, 3])\n",
      "Mixed_7a.branch3x3_2.bn.weight \t torch.Size([320])\n",
      "Mixed_7a.branch3x3_2.bn.bias \t torch.Size([320])\n",
      "Mixed_7a.branch3x3_2.bn.running_mean \t torch.Size([320])\n",
      "Mixed_7a.branch3x3_2.bn.running_var \t torch.Size([320])\n",
      "Mixed_7a.branch3x3_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7a.branch7x7x3_1.conv.weight \t torch.Size([192, 768, 1, 1])\n",
      "Mixed_7a.branch7x7x3_1.bn.weight \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_1.bn.bias \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_1.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_1.bn.running_var \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7a.branch7x7x3_2.conv.weight \t torch.Size([192, 192, 1, 7])\n",
      "Mixed_7a.branch7x7x3_2.bn.weight \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_2.bn.bias \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_2.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_2.bn.running_var \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7a.branch7x7x3_3.conv.weight \t torch.Size([192, 192, 7, 1])\n",
      "Mixed_7a.branch7x7x3_3.bn.weight \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_3.bn.bias \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_3.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_3.bn.running_var \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_3.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7a.branch7x7x3_4.conv.weight \t torch.Size([192, 192, 3, 3])\n",
      "Mixed_7a.branch7x7x3_4.bn.weight \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_4.bn.bias \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_4.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_4.bn.running_var \t torch.Size([192])\n",
      "Mixed_7a.branch7x7x3_4.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch1x1.conv.weight \t torch.Size([320, 1280, 1, 1])\n",
      "Mixed_7b.branch1x1.bn.weight \t torch.Size([320])\n",
      "Mixed_7b.branch1x1.bn.bias \t torch.Size([320])\n",
      "Mixed_7b.branch1x1.bn.running_mean \t torch.Size([320])\n",
      "Mixed_7b.branch1x1.bn.running_var \t torch.Size([320])\n",
      "Mixed_7b.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3_1.conv.weight \t torch.Size([384, 1280, 1, 1])\n",
      "Mixed_7b.branch3x3_1.bn.weight \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_1.bn.bias \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_1.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_1.bn.running_var \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3_2a.conv.weight \t torch.Size([384, 384, 1, 3])\n",
      "Mixed_7b.branch3x3_2a.bn.weight \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2a.bn.bias \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2a.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2a.bn.running_var \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2a.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3_2b.conv.weight \t torch.Size([384, 384, 3, 1])\n",
      "Mixed_7b.branch3x3_2b.bn.weight \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2b.bn.bias \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2b.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2b.bn.running_var \t torch.Size([384])\n",
      "Mixed_7b.branch3x3_2b.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3dbl_1.conv.weight \t torch.Size([448, 1280, 1, 1])\n",
      "Mixed_7b.branch3x3dbl_1.bn.weight \t torch.Size([448])\n",
      "Mixed_7b.branch3x3dbl_1.bn.bias \t torch.Size([448])\n",
      "Mixed_7b.branch3x3dbl_1.bn.running_mean \t torch.Size([448])\n",
      "Mixed_7b.branch3x3dbl_1.bn.running_var \t torch.Size([448])\n",
      "Mixed_7b.branch3x3dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3dbl_2.conv.weight \t torch.Size([384, 448, 3, 3])\n",
      "Mixed_7b.branch3x3dbl_2.bn.weight \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_2.bn.bias \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_2.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_2.bn.running_var \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3dbl_3a.conv.weight \t torch.Size([384, 384, 1, 3])\n",
      "Mixed_7b.branch3x3dbl_3a.bn.weight \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3a.bn.bias \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3a.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3a.bn.running_var \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3a.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch3x3dbl_3b.conv.weight \t torch.Size([384, 384, 3, 1])\n",
      "Mixed_7b.branch3x3dbl_3b.bn.weight \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3b.bn.bias \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3b.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3b.bn.running_var \t torch.Size([384])\n",
      "Mixed_7b.branch3x3dbl_3b.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7b.branch_pool.conv.weight \t torch.Size([192, 1280, 1, 1])\n",
      "Mixed_7b.branch_pool.bn.weight \t torch.Size([192])\n",
      "Mixed_7b.branch_pool.bn.bias \t torch.Size([192])\n",
      "Mixed_7b.branch_pool.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7b.branch_pool.bn.running_var \t torch.Size([192])\n",
      "Mixed_7b.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch1x1.conv.weight \t torch.Size([320, 2048, 1, 1])\n",
      "Mixed_7c.branch1x1.bn.weight \t torch.Size([320])\n",
      "Mixed_7c.branch1x1.bn.bias \t torch.Size([320])\n",
      "Mixed_7c.branch1x1.bn.running_mean \t torch.Size([320])\n",
      "Mixed_7c.branch1x1.bn.running_var \t torch.Size([320])\n",
      "Mixed_7c.branch1x1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3_1.conv.weight \t torch.Size([384, 2048, 1, 1])\n",
      "Mixed_7c.branch3x3_1.bn.weight \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_1.bn.bias \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_1.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_1.bn.running_var \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3_2a.conv.weight \t torch.Size([384, 384, 1, 3])\n",
      "Mixed_7c.branch3x3_2a.bn.weight \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2a.bn.bias \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2a.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2a.bn.running_var \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2a.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3_2b.conv.weight \t torch.Size([384, 384, 3, 1])\n",
      "Mixed_7c.branch3x3_2b.bn.weight \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2b.bn.bias \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2b.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2b.bn.running_var \t torch.Size([384])\n",
      "Mixed_7c.branch3x3_2b.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3dbl_1.conv.weight \t torch.Size([448, 2048, 1, 1])\n",
      "Mixed_7c.branch3x3dbl_1.bn.weight \t torch.Size([448])\n",
      "Mixed_7c.branch3x3dbl_1.bn.bias \t torch.Size([448])\n",
      "Mixed_7c.branch3x3dbl_1.bn.running_mean \t torch.Size([448])\n",
      "Mixed_7c.branch3x3dbl_1.bn.running_var \t torch.Size([448])\n",
      "Mixed_7c.branch3x3dbl_1.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3dbl_2.conv.weight \t torch.Size([384, 448, 3, 3])\n",
      "Mixed_7c.branch3x3dbl_2.bn.weight \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_2.bn.bias \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_2.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_2.bn.running_var \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_2.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3dbl_3a.conv.weight \t torch.Size([384, 384, 1, 3])\n",
      "Mixed_7c.branch3x3dbl_3a.bn.weight \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3a.bn.bias \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3a.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3a.bn.running_var \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3a.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch3x3dbl_3b.conv.weight \t torch.Size([384, 384, 3, 1])\n",
      "Mixed_7c.branch3x3dbl_3b.bn.weight \t torch.Size([384])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mixed_7c.branch3x3dbl_3b.bn.bias \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3b.bn.running_mean \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3b.bn.running_var \t torch.Size([384])\n",
      "Mixed_7c.branch3x3dbl_3b.bn.num_batches_tracked \t torch.Size([])\n",
      "Mixed_7c.branch_pool.conv.weight \t torch.Size([192, 2048, 1, 1])\n",
      "Mixed_7c.branch_pool.bn.weight \t torch.Size([192])\n",
      "Mixed_7c.branch_pool.bn.bias \t torch.Size([192])\n",
      "Mixed_7c.branch_pool.bn.running_mean \t torch.Size([192])\n",
      "Mixed_7c.branch_pool.bn.running_var \t torch.Size([192])\n",
      "Mixed_7c.branch_pool.bn.num_batches_tracked \t torch.Size([])\n",
      "fc.weight \t torch.Size([101, 2048])\n",
      "fc.bias \t torch.Size([101])\n"
     ]
    }
   ],
   "source": [
    "# Print model's state_dict\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model_inception.state_dict():\n",
    "    print(param_tensor, \"\\t\", model_inception.state_dict()[param_tensor].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to /home/foodlovers/FoodVisor/trained_models/InceptionV3/model_9_epoch.pt ...\n",
      "Done !\n"
     ]
    }
   ],
   "source": [
    "path_save = '/home/foodlovers/FoodVisor/trained_models/InceptionV3/model_9_epoch.pt'\n",
    "print(\"Saving model to\",path_save,\"...\")\n",
    "torch.save(model_inception.state_dict(), path_save)\n",
    "print(\"Done !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(train=False,validate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot loss & accuracy history\n",
    "I forgot to return the history, so I do it by hand ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "history=[[0.1224 ,0.0915 ,0.0763 ,0.0648 ,0.0549 ,0.0466 ,0.0392 ,0.0333 ,0.0274 ],\n",
    "[0.3394,0.4945,0.5691,0.6249,0.6760,0.7152,0.7521,0.7811,0.8165],\n",
    "[0.0732 ,0.0719 ,0.0628 ,0.0639 ,0.0619 ,0.0638 ,0.0651 ,0.0664 ,0.0711 ],\n",
    "[0.4549 ,0.4576 ,0.5349 ,0.5314 ,0.5581 ,0.5561 ,0.5637 ,0.5573 ,0.5578 ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Loss history')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VOX5xvHvQxII+yaiEBUXtAZQxIC1WtytWBEVFaxal7bIr9WqVCvaKoq17iKorVKXYl2QirS4UFqroq1WQMQFkU0RIsi+iAhJyPP7451IDFkmZJIzy/25rrkyc+bMzDMu9znznncxd0dERDJDo6gLEBGRhqPQFxHJIAp9EZEMotAXEckgCn0RkQyi0BcRySAKfZEqmNmFZvafap6fYmYXNGRNInWl0JekZ2aLzez4qOuoyN37ufu4mvYzMzez/RqiJpGaKPRFkpiZZUddg6QXhb6kNDP7mZktNLO1ZjbZzDrFtpuZjTKzlWa2wczeN7PusedONrOPzOxLM/vczK6q4TPuMrN1ZvapmfUrt/01M/tp7P5+ZjYt9lmrzeyZ2PbXY7u/Z2abzGxQdXXHnnMz+4WZLQAWmNkDZnZ3hZqeN7Mr6v5PUDKNQl9SlpkdC9wKnA3sDnwGjI89fSLQF9gfaAMMAtbEnnsEuMTdWwLdgVeq+ZjDgHnALsAdwCNmZpXsdzPwT6AtkAfcB+DufWPPH+zuLdz9mRrqLnNa7LPzgXHAOWbWKPa9dwGOA56upm6RSin0JZWdCzzq7rPcfStwLXC4mXUBioGWwHcAc/e57r489rpiIN/MWrn7OnefVc1nfObuf3L3bYTw3R3oWMl+xcBeQCd33+LuVV4ArqHuMre6+1p3/9rdpwMbCEEPMBh4zd1XVPMZIpVS6Esq60Q4SwbA3TcRzuY7u/srwP3AA8AKMxtrZq1iuw4ETgY+izXJHF7NZ3xR7v03x+62qGS/XwMGTDezOWZ28c7UXW6fpRVeMw44L3b/POAv1by/SJUU+pLKlhHOrgEws+ZAe+BzAHcf4+6HAt0IzTxXx7bPcPcBwK7A34AJdS3E3b9w95+5eyfgEuAP1fTYqbbusres8JongAFmdjBwYKxukVpT6EuqyDGz3HK3bOAp4CIz62lmTYDfA2+7+2Iz621mh5lZDvAVsAXYZmaNzexcM2vt7sXARmBbXYszs7PMLC/2cB0htMvedwWwT7ndq6y7qvd390JgBuEMf6K7f13XmiUzKfQlVbwEfF3udqO7/xu4HpgILAf2JbR3A7QC/kQI4M8IzSd3xZ47H1hsZhuBoWxvNqmL3sDbZrYJmAxc7u6fxp67ERhnZuvN7Owa6q7OOKAHatqROjAtoiKSGsysL6GZp4u7l0Zdj6QmnemLpIBYM9XlwMMKfKkLhb5IkjOzA4H1hO6i90ZcjqQ4Ne+IiGQQnemLiGSQpJvMaZdddvEuXbpEXYaISEp55513Vrt7h5r2S7rQ79KlCzNnzoy6DBGRlGJmn9W8l5p3REQyikJfRCSDKPRFRDJI0rXpi4jURnFxMYWFhWzZsiXqUhpEbm4ueXl55OTk7NTrFfoiktIKCwtp2bIlXbp0ofL1bdKHu7NmzRoKCwvZe++9d+o91LwjIilty5YttG/fPu0DH8DMaN++fZ1+1Sj0RSTlZULgl6nrd02f0N+0Ca69FhYtiroSEZGklT6hv2ED3HcfDBsWdSUikkHWrFlDz5496dmzJ7vtthudO3f+5nFRUVFc73HRRRcxb968eq40SJ8LuZ07w/XXw/DhMGUK9OsXdUUikgHat2/P7NmzAbjxxhtp0aIFV1111bf2cXfcnUaNKj/Pfuyxx+q9zjJxnemb2UlmNs/MFprZ8Eqe72tms8ysxMzOLLe9p5m9FVso+n0zG5TI4ndwxRWw//5w+eWwdWu9fpSISHUWLlxI9+7dGTp0KL169WL58uUMGTKEgoICunXrxsiRI7/Z98gjj2T27NmUlJTQpk0bhg8fzsEHH8zhhx/OypUrE1pXjWf6ZpYFPACcABQCM8xssrt/VG63JcCFwFUVXr4Z+LG7LzCzTsA7ZjbV3dcnpPqKmjSB0aPDWf6oUeGsX0QyxxVXQOysO2F69oR7d24Zg48++ojHHnuMBx98EIDbbruNdu3aUVJSwjHHHMOZZ55Jfn7+t16zYcMGjjrqKG677TaGDRvGo48+yvAEZlk8Z/p9gIXu/om7FwHjgQHld3D3xe7+PlBaYft8d18Qu78MWAnUOAtcnZx0EgwYAL/7HRQW1utHiYhUZ99996V3797fPH766afp1asXvXr1Yu7cuXz00Uc7vKZp06b0izVPH3rooSxevDihNcXTpt8ZWFrucSFwWG0/yMz6AI2BHbrXmNkQYAjAnnvuWdu33tE990B+Plx9NTz9dN3fT0RSw06ekdeX5s2bf3N/wYIFjB49munTp9OmTRvOO++8SvvbN27c+Jv7WVlZlJSUJLSmeM70K+sUWqvltsxsd+AvwEWVre/p7mPdvcDdCzp0SMAPgX32gWuugfHjYdq0ur+fiEgdbdy4kZYtW9KqVSuWL1/O1KlTI6kjntAvBPYo9zgPWBbvB5hZK+BF4Lfu/r/alVcH11wDe+4Jl10GCT5SiojUVq9evcjPz6d79+787Gc/44gjjoikjhrXyDWzbGA+cBzwOTAD+JG7z6lk3z8DL7j7s7HHjYEpwPPuHtfvroKCAk/YIirPPQcDB8KYMSH8RSTtzJ07lwMPPDDqMhpUZd/ZzN5x94KaXlvjmb67lwCXAlOBucAEd59jZiPN7NTYh/U2s0LgLOAhMys7IJwN9AUuNLPZsVvP2ny5Ojn9dDj++NB/P8HdnkREUlFcg7Pc/SXgpQrbbih3fwah2afi654AnqhjjTvPLJzlH3QQXHcdPPxwZKWIiCSD9JmGoSoHHhgGaz3yCEyfHnU1IiKRSv/QB7jhBthtN7j0UijdofOQiEjGyIzQb9UK7rgDZsyABpzjQkQk2WRG6AOcdx4ccUSYfnl9/cwCISKS7DIn9M3C1MurV8OIEVFXIyJpIhFTKwM8+uijfPHFF/VYaZA5oQ9wyCEwdCg88AB88EHU1YhIGiibWnn27NkMHTqUK6+88pvH5adUqIlCv77cfDO0bh0Ga9UwME1EpC7GjRtHnz596NmzJz//+c8pLS2lpKSE888/nx49etC9e3fGjBnDM888w+zZsxk0aFCtfyHUVvosohKv9u3hllvg//4PnnkGBg+OuiIRSZR3roB1CZ5auW1POLT2E7l9+OGHTJo0iTfffJPs7GyGDBnC+PHj2XfffVm9ejUfxFob1q9fT5s2bbjvvvu4//776dmzfsevZt6ZPsDPfhaaeq66KqytKyKSYC+//DIzZsygoKCAnj17Mm3aNBYtWsR+++3HvHnzuPzyy5k6dSqtW7du0Loy70wfICsL7r8/9Oa55Ra49daoKxKRRNiJM/L64u5cfPHF3HzzzTs89/777zNlyhTGjBnDxIkTGTt2bIPVlZln+gDf+x78+Mdw990wf37U1YhImjn++OOZMGECq1evBkIvnyVLlrBq1SrcnbPOOoubbrqJWbNmAdCyZUu+/PLLeq8rM8/0y9x+O0yaFJZYe/HF0K1TRCQBevTowYgRIzj++OMpLS0lJyeHBx98kKysLH7yk5/g7pgZt99+OwAXXXQRP/3pT2natCnTp0+vVc+f2qhxauWGltCpleNxzz3wq1/B5MnQv3/Dfa6IJISmVg4SNrVy2rvssjAp2xVXQCVLl4mIpBOFfk5OmH75k0/grruirkZEpF4p9CEstDJwIPz+9/DZZ1FXIyK1lGzN1PWprt9VoV/m7rvD36uuirYOEamV3Nxc1qxZkxHB7+6sWbOG3NzcnX6PzO69U95ee4UZOG+4Af79bzjuuKgrEpE45OXlUVhYyKpVq6IupUHk5uaSl7fDQoVxU++d8rZsgW7doEkTeO+90N4vIpIC1HtnZ+TmwqhRMHduGLErIpJmFPoV9e8P/fqFOfcbYJpTEZGGpNCvyAzuvTc09QwfHnU1IiIJpdCvzP77h1G648bBm29GXY2ISMIo9Kvym99A585hxO62bVFXIyKSEAr9qrRoEUbozpoFDz8cdTUiIgmh0K/OoEFw1FFw3XWwZk3U1YiI1JlCvzpmYV6eDRvg+uujrkZEpM4U+jU56CD4+c/hoYfg3XejrkZEpE4U+vG46SZo1y5c1E2yEcwiIrWh0I9H27Zw223w3//Ck09GXY2IyE5T6Mfroougd2+4+mrYuDHqakREdopCP16NGoX5eL74AipZ3V5EJBUo9GujTx+4+OIwTcPcuVFXIyJSa3GFvpmdZGbzzGyhme0wIY2Z9TWzWWZWYmZnVnjuAjNbELtdkKjCI3PrrdC8Ofzyl7qoKyIpp8bQN7Ms4AGgH5APnGNm+RV2WwJcCDxV4bXtgBHAYUAfYISZta172RHadVcYORJefhkmTYq6GhGRWonnTL8PsNDdP3H3ImA8MKD8Du6+2N3fB0orvPYHwL/cfa27rwP+BZyUgLqj9fOfQ/fuMGwYbN4cdTUiInGLJ/Q7A0vLPS6MbYtHXK81syFmNtPMZqbEkmfZ2eGi7mefwR13RF2NiEjc4gl9q2RbvI3Zcb3W3ce6e4G7F3To0CHOt47YUUfB4MGh//6nn0ZdjYhIXOIJ/UJgj3KP84Blcb5/XV6b/O68E7KyQjOPiEgKiCf0ZwBdzWxvM2sMDAYmx/n+U4ETzaxt7ALuibFt6SEvL0zE9re/wdT0+Voikr5qDH13LwEuJYT1XGCCu88xs5FmdiqAmfU2s0LgLOAhM5sTe+1a4GbCgWMGMDK2LX1ceSV07Rq6cBYVRV2NiEi1zJOsr3lBQYHPnDkz6jJqZ8oUOPlkuP12+PWvo65GRDKQmb3j7gU17acRuYnQrx/07x+mZ/j886irERGpkkI/UUaNguJinemLSFJT6CfKvvuGGTifegpefz3qakREKqXQT6Rrr4U99wyLrZSURF2NiMgOFPqJ1KwZ3H03vP9+WF5RRCTJKPQTbeBAOPZY+O1vIRWmlBCRjKLQTzQzuO8+2LQJfvObqKsREfkWhX59yM8P7foPPwypNuZARNKaQr++jBgR5t6/9FIorTjjtIhINBT69aV16zBC9+234fHHo65GRARQ6Nev88+Hww+Ha66BDRuirkZERKFfrxo1CoutrFoFp5yi3jwiEjmFfn3r1Quefjpc0O3TBz78MOqKRCSDKfQbwqBBMG0abN0amnteeCHqikQkQyn0G0qfPjBjBhxwAJx6alh1K8mmtRaR9KfQb0idO4fJ2M48M8zGedFF4exfRKSBKPQbWrNm8MwzcOONMG5cmLJh5cqoqxKRDKHQj4JZGLw1YQK8+y707h0maRMRqWcK/SiddRa88UaYhvl734O//z3qikQkzSn0o3booeECb34+nH463HqrLvCKSL1R6CeDTp1Cl85Bg+C66+DHP4YtW6KuSkTSkEI/WTRtGpZavPlmeOIJOOYY+OKLqKsSkTSj0E8mZmHxlWefDRd2+/SB2bOjrkpE0ohCPxkNHAj/+U9o2z/iCHjuuagrEpE0odBPVoccEi7w9ugRDgK33KILvCJSZwr9ZLbbbvDaa3DuuaHZ59xz4euvo65KRFKYQj/Z5ebCX/4SunKOHw9HHw3Ll0ddlYikKIV+KjCD4cNh0iSYMyeM4J01K+qqRCQFKfRTyYAB8N//QlYWHHlk6OUjIlILCv1Uc/DBMH16uNB71lkwcqQu8IpI3BT6qahjR3jllTByd8QIGDwYNm+OuioRSQEK/VTVpAn8+c9wxx3w17/CUUfB559HXZWIJLm4Qt/MTjKzeWa20MyGV/J8EzN7Jvb822bWJbY9x8zGmdkHZjbXzK5NbPkZzgyuvjrMzvnxx+EC74wZUVclIkmsxtA3syzgAaAfkA+cY2b5FXb7CbDO3fcDRgG3x7afBTRx9x7AocAlZQcESaD+/eHNN8PZf9++YZEWEZFKxHOm3wdY6O6fuHsRMB4YUGGfAcC42P1ngePMzAAHmptZNtAUKAI2JqRy+bYePcIF3t69Qxv/DTdAaWnUVYlIkokn9DsDS8s9Loxtq3Qfdy8BNgDtCQeAr4DlwBLgLndfW/EDzGyImc00s5mrVq2q9ZeQmA4d4OWX4eKLw2ydZ58NX30VdVUikkTiCX2rZFvFPoJV7dMH2AZ0AvYGfmVm++ywo/tYdy9w94IOHTrEUZJUqXFjePhhuPvuMJjr+9+HwsKoqxKRJBFP6BcCe5R7nAcsq2qfWFNOa2At8CPgH+5e7O4rgf8CBXUtWmpgBsOGwfPPw8KFocnn7bejrkpEkkA8oT8D6Gpme5tZY2AwMLnCPpOBC2L3zwRecXcnNOkca0Fz4LvAx4kpXWp08snwv/9Bs2ahS+dTT0VdkYhErMbQj7XRXwpMBeYCE9x9jpmNNLNTY7s9ArQ3s4XAMKCsW+cDQAvgQ8LB4zF3fz/B30Gqk58fzvK/+90wS+dvfqMLvCIZzDzJhvAXFBT4zJkzoy4j/RQVwaWXwp/+FBZgf/xxaNEi6qpEJEHM7B13r7H5XCNyM0XjxvDQQzB6dBjMdeSRsGRJ1FWJSANT6GcSM/jlL+Gll2Dx4nCB99//jroqEWlACv1M9IMfhAu8bdrA8cfDhRfC6tVRVyUiDUChn6m+8x2YPRuuuw6efDI8fvxxTdMskuYU+pmsadOw4Pq778IBB8AFF8AJJ8CCBVFXJiL1RKEv0L07vPEG/PGPMHNmmMfnlltCjx8RSSsKfQkaNYKhQ2HuXDj1VPjtb6FXr7A8o4ikjfQJfS+FjfNhy2ooLYm6mtS1++4wYQK88AJ8+WXo2jl0KKxfH3VlIpIA2VEXkDBb18ILB2x/nNMGmrSDxrFbk3bQuH0N29pCo/T5R1InP/whzJkTlmO8997Qt3/06LAur1U2v56IpIL0GZFbshmWToKitbB1TfhbtDYcDL65vwaK1rHjJKHl5LSK4+BQcVtbaJSz09856c2aBUOGwDvvhPl8/vAH2GuvqKsSkXLiHZGbPqEfLy+F4g3bDwZlB4gdDg4VthWtDa+tSnbLqg8OTXaBzv2h5X71973qW0kJ3H9/aOt3h5Ej4fLLIVu/jESSgUI/0bwUijd++2BQ6QFjLRRV2O7bwLKgy3nQ7TfQqmvU32bnLVkS5vB5/nk45BAYOxYKNFu2SNQU+snCHb7+HD4eBQv+CKVbYa9zoftvodX+UVe3c9zhuefgsstgxYrw9+aboWXLqCsTSS3usGkRrHgVVrwSmpf7PLRTb6UJ15KFGTTLg153w6mfwgFXwtJn4cUD4c3zYeO8qCusPTMYODB07xw6FMaMgW7dYHLFZRZEZAdfLYVPHoe3LoS/7wXPd4XpQ2DlNLD6vzaoM/0ofL0CPr4L5v8BSrfAXudAt99C6+9EXdnOeeutcKH3ww/hjDPCQaBzxWWURTLUlpXbz+S/eAU2LQzbm7SHXY+B3Y6FjsdCy/3r1DNOzTupYMtKmHsXzH8Atn0dwr/7b6H1gVFXVnvFxWFd3ptugpwcuPXW8CsgKyvqykQaVtE6WDEthPyKV2HDh2F7TivY9agQ8B2PgTY9wBLX2KLQTyVbVsHHd8P8+0PX070GQffroXV+1JXV3qJF8H//B//6Fxx2WLjQe9BBUVclUn+KN8GqN7afza+dBThkNYUO3w9n8rseA+161es4IIV+KtqyOhb+94Xw3/PsEP5tukVdWe24h/V4r7wS1q2DX/0KbrghrNUrkuq2bYHVb4WmmhWvwJrp4CXQqDHscng4i+94LLTvA1lNGqwshX4q27IaPr4nFv5fwZ5nxcK/e9SV1c6aNfDrX8Ojj8Lee8ODD8KJJ0ZdlUjtlBbDmhmx5ppXYNWboReeZUG7ghDwux0Lu3wPsqM7sVHop4Ota0L4zxsDJZti4X9D6oX/tGlwySUwbx786EcwahTsumvUVYlUrnQbrJ8dO5N/FVa9Hk6+ANr2jLXJHwu7fj+00ycJhX462bom9POfNwZKvoQ9zoQeN4QLQali69ZwcffWW6F5c7jzTrj4Ys3jI9Fzhw1ztrfJr3gNimMTDLY6cPuZ/K5HhR43SUqhn462rg3hP39MGB28xxnhzL/twVFXFr+PPw5n/a+/Dn37hsXav5OiXVUlNX0zICrWhXLlq6EnHUCLfbb3rul4DDTdPdpaa0Ghn86K1sHH98K8e0P4550ezvzb9oy6sviUlsJjj8HVV8NXX8G114Zbk4a76CVpYtvWyidYrG7b1jWwbXN4fdNO25trOh4DLbpE+nXqQqGfCYrWwcejY+G/AfJOC2f+7Q6JurL4rFgBw4aFnj4HHBDO+o86KuqqJAolX9cuuMu2lYV3ZSw7NMd8Mytu2SSI7aFl19iAqK5p08So0M8kReth3ujQ9FO8AfIGxMK/V9SVxWfq1NC3/9NPQzv/nXdCu3ZRVyW15R4GGZafeLCyyQgr27ZtS9Xv2yjn27PXlgV5+TCvbFt2i7QJ9Hgo9DNR0fpwsffjUeFCVOf+0GMEtDs06spqtnlzmK75rrtC4N92W1ioXSN6G557OIOuzRl3WZiXbq36fRs1joVzvOtVxMI8q1lGhffOUuhnsqINsfC/J4R/p1NC+LdPgSmQ338/TN/w1lthErdbb4VTTtH/9DvDPXQ1rGqdiOrCvLSo6vfNyt2JhYbahRGq+vdYbxT6EsJ//n0h/IvWQacfxsK/d8PVUBY8xRvCL5Hyf6vctgHWboYZi+DTjdC+K5zzCzj0hDBjaRL1jW5w24rg62Wx2+ewOfZ366rKFwIqLa76vbKa7djWXVn7d8Vt2U0b7vtK3BT6sl3xxjCvz9y7QxB0Ohm6j4Bd+tT82m1FFUJ5fQjlb/5W9lyFEPdt1X+GZUPjNpDTOnZrFWreXAhbV+64f3bLEP4Vb03L3W/cNrXOKr0Utq4OYb7583J/P//2tq2rdnxtoyaQu2vtgrtJu3DGLmlDoS87Kv4yFv53hfDf/aQwurdiiJcP9uousJXJaRXCunxwl92PZ1t1P/u3bYXVC+DxUfDSk9CiCPp2h557QunqcGDYsnzHpSyzmlZ+MCh/a7JLQmc5rFLxpnJn5hVCvCzUv15WyVm5QW7H0K2wWefwt2nn7ffL/jZul1oHOKkXCn2pWvGXYTrnj+8JI3y/FcRtoHHrmreV/c1uCY0a6GLrypVhha4HH4TGjcNEblddBS2awZYvwgGg4u3rsvufh0mxymvUOBai1fxqyO1Y9fcrLYYtK7afkW9eVuHMPHa/eOOOr81uGQvtCgFeflvT3ULPFZE4KPSlZu6peYa4cGFYoP2ZZ6BDB7j++jDKt3Hjql/jpWHUZaUHhHK3ir1PLCsWxnkhjEu3bj9L37ICqPD/j2VXcmZe4Qy9aSfI0dKSklgKfUl/M2bANdfAq6/CPvvALbfA2WdDo51ssnEPF0ArOxiUHSQaNamkiaXc/YZqMhKpIKGhb2YnAaOBLOBhd7+twvNNgMeBQ4E1wCB3Xxx77iDgIaAVUAr0dvcqG4oV+lIr7mFw1zXXhO6ehx4Kt98Oxx0XdWUiDSphC6ObWRbwANAPyAfOMbOKSzr9BFjn7vsBo4DbY6/NBp4Ahrp7N+BooJo+ZCK1ZAYnnQTvvguPPw6rVsHxx4dt770XdXUiSSee36F9gIXu/om7FwHjgQEV9hkAjIvdfxY4zswMOBF4393fA3D3Ne419d8T2QmNGsH554c5++++G6ZPh0MOCdsWL466OpGkEU/odwaWlntcGNtW6T7uXgJsANoD+wNuZlPNbJaZ/bqyDzCzIWY208xmrlpVST9kkXjl5oZJ3D75JKza9eyzYTK3X/0qrOQlkuHiCf3KundUvBBQ1T7ZwJHAubG/p5vZDo2t7j7W3QvcvaBDhw5xlCRSgzZtwvw9CxbAeefBvffCvvuGbZurmZlRJM3FE/qFwB7lHucBy6raJ9aO3xpYG9s+zd1Xu/tm4CUgRaZ+lLSQlwePPBIu8vbtG+bt33//sK2kpObXi6SZeEJ/BtDVzPY2s8bAYGByhX0mAxfE7p8JvOKhW9BU4CAzaxY7GBwFfJSY0kVqoVs3mDw5rNi1xx7w05/CwQeHbUnWbVmkPtUY+rE2+ksJAT4XmODuc8xspJmdGtvtEaC9mS0EhgHDY69dB9xDOHDMBma5+4uJ/xoicfr+9+HNN2HixHCmP2BA+AXw1ltRVybSIDQ4SzJXcTE8+ijceCN88QWcfnqYyvmAA6KuTKTWEtZPXyRt5eSE6RsWLgxz+rz8cmgGuuQSWL486upE6oVCX6R58zCXz6JF8ItfhEXb99svbNtYyWRpIilMoS9SpkMHGD0a5s6FU08Nc/nsu2/YtrWaZQBFUohCX6SiffeFp58OE7oddBBccQUceGDYVlpa8+tFkphCX6QqBQWhnf8f/4BWreBHP4IePULzj878JUUp9EWqYwY/+AHMmgVPPRUu/l58MXTpEnr6rFsXdYUitaLQF4lHo0ZwzjlhNs9//jM0+1x3XRjodcUVmtRNUoZCX6Q2zOCEE8Ic/u+9BwMHwgMPhOsAgweDxphIklPoi+ysgw6CcePg00/DLJ5TpkDv3nD00fDii7roK0lJoS9SV3l5cMcdsHRpmMv/k0/glFOge/cwsduWKheKE2lwCn2RRGnVKszlv2gRPPkkNGkSJnbr0iX0+V+7NuoKRRT6IgmXkxO6d86aFbp8HnJIGN27xx7wy1+GXwIiEVHoi9QXs7BA+5QpYT7/s8+GBx+Erl3D/enTo65QMpBCX6QhlA3q+vRTuPrq0O3zsMPCtM7PP6+LvtJgFPoiDalz57Bk49KlMGoUfPZZmOcnPx/+9Cdd9JV6p9AXiULLlmFQ16JFYaRv8+YwZAjstRf87ndaxF3qjUJfJErZ2WGk78yZ8MorYb6f668PF30vvTQcFEQSSKEvkgzM4JhjwqCuDz8Mo3vHjg2LuJ91Frz9dtQVSppQ6Iskm27dwjKOn30G11wTun1+97thfd+//10XfaVOFPoiyWr33eH3vw8XfUePhsKCV3BMAAALAElEQVRCOO20MLf/2LHw9ddRVygpSKEvkuxatAiDuhYsgPHjw0XgSy4JF31HjoTVq6OuUFKIQl8kVWRnw6BBYUWvV1+FPn1gxAjYc8/Q82fWrKgrlBSg0BdJNWZhJs8XXoA5c8KUD088AYceGg4EjzwCX30VdZWSpBT6IqksPx8efhiWLYMxY2Dz5jDJW6dOocvnBx9EXaEkGYW+SDpo0wYuuyyE/BtvQP/+4WBw0EFw5JHwl7/owq8ACn2R9GIWQv6JJ0Jvn7vugpUr4cc/DvP+DxsG8+ZFXaVESKEvkq522SWs6DVvHvz732HGz/vug+98B449Fp55BoqKoq5SGphCXyTdmYWQnzAh9Pn//e/DbJ+DB4fpHoYP1xz/GUShL5JJdtsNrr02zOkzZQocfjjceWdY2P2kk2DSJCgpibpKqUcKfZFM1KhRCPm//S1M93DjjWHOnzPOCIO+brgBliyJukqpBwp9kUyXlxcGeS1eHOb2OfjgML3z3nuHuf5ffBG2bYu6SkkQhb6IBNnZIeRfeim08Q8fHpZ0POUU2GefcCBYvjzqKqWOFPoisqMuXeCWW0ITz1//Gtb1vf76MOXDmWfCv/6l2T5TVFyhb2Ynmdk8M1toZsMreb6JmT0Te/5tM+tS4fk9zWyTmV2VmLJFpEE0bhxC/uWXYf78sNrXa6/BiSeGuf7vuANWrYq6SqmFGkPfzLKAB4B+QD5wjpnlV9jtJ8A6d98PGAXcXuH5UcCUupcrIpHp2jX09CkshCefDFM9XHNNuCZwzjkwbRq4R12l1CCeM/0+wEJ3/8Tdi4DxwIAK+wwAxsXuPwscZ2YGYGanAZ8AcxJTsohEKjc3TPL2+uthwrehQ0P3z6OPDnMB3XsvrF0bdZVShXhCvzOwtNzjwti2Svdx9xJgA9DezJoD1wA3VfcBZjbEzGaa2cxV+qkokjry88MCL8uWwWOPQevWcOWV0LkzXHBBaApSz5+kEk/oWyXbKv6Gq2qfm4BR7r6pug9w97HuXuDuBR06dIijJBFJKs2awYUXwv/+B+++G+4/91xY93f33cN8///4h6Z9SALxhH4hsEe5x3nAsqr2MbNsoDWwFjgMuMPMFgNXANeZ2aV1rFlEklnPnvDHP4bunRMmhCkgnn4a+vWDjh3D5G9/+5tm/YyIeQ0XXmIhPh84DvgcmAH8yN3nlNvnF0APdx9qZoOBM9z97ArvcyOwyd3vqu7zCgoKfObMmTvzXUQkWW3ZErp5TpwIkyfDunXh18HJJ8PAgfDDH4ZlIGWnmdk77l5Q037ZNe3g7iWxs/OpQBbwqLvPMbORwEx3nww8AvzFzBYSzvAH1618EUkrublhjv/+/aG4OLT1T5wY5vp59llo0gROOCEcAE49Fdq1i7ritFXjmX5D05m+SAbZtg3efDO0/0+cGGYBzcoK1wIGDoTTTguTxEmN4j3TV+iLSHJwh5kztx8AFiwI00IfcUSYCK5sMjiplEJfRFKXexgDMHFiuJWt9VtQEMJ/4MAwIli+odAXkfSxYMH2XwAzZoRt3btvPwD06BF+FWQwhb6IpKclS8IF4OeeC4vAu8N++20/APTunZEHAIW+iKS/FSvCGgATJ8Irr4RVv/Lyth8AjjgiXBjOAAp9Ecksa9fCCy+EA8DUqbB1K+y6a+gBdMYZYZBYTk7UVdYbhb6IZK5Nm8JiMBMnhpW/vvoK2rQJYwDOOCNMDd20adRVJpRCX0QEwnQP5UcDr18PzZuHUcBnnBFGBafBaGCFvohIRcXF8Oqr4SLwpEmwcmUYDXziidtHA7dtG3WVO0WhLyJSnbLRwBMnhoPA0qVhneDyo4E7doy6yrgp9EVE4lU2GrhsMNjChaHb55FHhgPA6aeH9YGTmEJfRGRnuMOHH27/BVA2Grh37+1dQbt2jbbGSij0RUQSYf780P5ffjRwjx7bDwDduyfFYDCFvohIopWNBp44Ef7zn/CroGvX7QeAgoLIDgAKfRGR+rRiRVgB7Lnnto8G3mOP7TOCNvBoYIW+iEhDWbsWnn8+HADKRgN37Lh9NPAxx9T7aGCFvohIFL78EqZM+fZo4LZtvz0aODc34R+r0BcRiVplo4FbtNi+NvDJJ4fHCaDQFxFJJmWjgSdODNcCykYD/+AH4QDQv3+dRgPHG/qNdvoTREQkfjk5oWnnoYdg2TKYNg2GDoV334ULLggzgg4eXO9lZNf7J4iIyLdlZUHfvuE2atT20cAN0NtHoS8iEiWzMNq3d+8G+Tg174iIZBCFvohIBlHoi4hkEIW+iEgGUeiLiGQQhb6ISAZR6IuIZBCFvohIBkm6uXfMbBXwWR3eYhdgdYLKSSTVVTuqq3ZUV+2kY117uXuHmnZKutCvKzObGc+kQw1NddWO6qod1VU7mVyXmndERDKIQl9EJIOkY+iPjbqAKqiu2lFdtaO6aidj60q7Nn0REalaOp7pi4hIFRT6IiIZJG1C38xOMrN5ZrbQzIZHXU8ZM3vUzFaa2YdR11LGzPYws1fNbK6ZzTGzy6OuCcDMcs1supm9F6vrpqhrKs/MsszsXTN7IepayjOzxWb2gZnNNrOkWWDazNqY2bNm9nHsv7XDk6CmA2L/nMpuG83siqjrAjCzK2P/3X9oZk+bWW69fE46tOmbWRYwHzgBKARmAOe4+0eRFgaYWV9gE/C4u3ePuh4AM9sd2N3dZ5lZS+Ad4LSo/3mZmQHN3X2TmeUA/wEud/f/RVlXGTMbBhQArdz9lKjrKWNmi4ECd0+qwUZmNg54w90fNrPGQDN3Xx91XWViufE5cJi712VAaCJq6Uz47z3f3b82swnAS+7+50R/Vrqc6fcBFrr7J+5eBIwHBkRcEwDu/jqwNuo6ynP35e4+K3b/S2Au0DnaqsCDTbGHObFbUpyVmFke8EPg4ahrSQVm1groCzwC4O5FyRT4MccBi6IO/HKygaZmlg00A5bVx4ekS+h3BpaWe1xIEoRYKjCzLsAhwNvRVhLEmlBmAyuBf7l7UtQF3Av8GiiNupBKOPBPM3vHzIZEXUzMPsAq4LFYk9jDZtY86qIqGAw8HXURAO7+OXAXsARYDmxw93/Wx2elS+hbJduS4gwxmZlZC2AicIW7b4y6HgB33+buPYE8oI+ZRd4kZmanACvd/Z2oa6nCEe7eC+gH/CLWpBi1bKAX8Ed3PwT4Ckima22NgVOBv0ZdC4CZtSW0TuwNdAKam9l59fFZ6RL6hcAe5R7nUU8/jdJFrM18IvCkuz8XdT0VxZoCXgNOirgUgCOAU2Nt5+OBY83siWhL2s7dl8X+rgQmEZo7o1YIFJb7pfYs4SCQLPoBs9x9RdSFxBwPfOruq9y9GHgO+F59fFC6hP4MoKuZ7R07gg8GJkdcU9KKXTB9BJjr7vdEXU8ZM+tgZm1i95sS/kf4ONqqwN2vdfc8d+9C+G/rFXevl7Ow2jKz5rGL8cSaT04EIu8p5u5fAEvN7IDYpuOAyDtWlHMOSdK0E7ME+K6ZNYv9/3kc4VpbwmXXx5s2NHcvMbNLgalAFvCou8+JuCwAzOxp4GhgFzMrBEa4+yPRVsURwPnAB7H2c4Dr3P2lCGsC2B0YF+tV0QiY4O5J1T0yCXUEJoWcIBt4yt3/EW1J37gMeDJ2IvYJcFHE9QBgZs0IPf0uibqWMu7+tpk9C8wCSoB3qacpGdKiy6aIiMQnXZp3REQkDgp9EZEMotAXEckgCn0RkQyi0BcRySAKfRGRDKLQFxHJIP8PAoWlNYztkiQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[0],color='red',label='Train')\n",
    "plt.plot(history[2],color='orange',label='Test')\n",
    "plt.legend()\n",
    "plt.plot()\n",
    "plt.title(\"Loss history\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Training accuracy history')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[1],color='red',label='Train')\n",
    "plt.plot(history[3],color='orange',label='Test')\n",
    "plt.legend()\n",
    "plt.plot()\n",
    "plt.title(\"Training accuracy history\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
