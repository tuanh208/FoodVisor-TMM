{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import os\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import torch\n",
    "import bcolz\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imp\n",
    "import utils; imp.reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "use_gpu = torch.cuda.is_available()\n",
    "print('Using gpu: %s ' % use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/foodlovers/FoodVisor/data/images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "         for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('/home/foodlovers/FoodVisor/data/images/train/apple_pie/apple_pie_0.jpg', 0),\n",
       " ('/home/foodlovers/FoodVisor/data/images/train/apple_pie/apple_pie_100.jpg',\n",
       "  0),\n",
       " ('/home/foodlovers/FoodVisor/data/images/train/apple_pie/apple_pie_101.jpg',\n",
       "  0),\n",
       " ('/home/foodlovers/FoodVisor/data/images/train/apple_pie/apple_pie_102.jpg',\n",
       "  0),\n",
       " ('/home/foodlovers/FoodVisor/data/images/train/apple_pie/apple_pie_104.jpg',\n",
       "  0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsets['train'].imgs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dset_loaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=32,\n",
    "                                               shuffle=False, num_workers=6)\n",
    "                for x in ['train', 'test']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_vgg = models.vgg16(pretrained=True)\n",
    "model_vgg.classifier._modules['6'] = nn.Linear(4096, 101)\n",
    "if use_gpu:\n",
    "    model_vgg = model_vgg.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate preconvoluted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preconvfeat(dataset):\n",
    "    conv_features = []\n",
    "    labels_list = []\n",
    "    count = 1\n",
    "    for data in dataset:\n",
    "        print(\"{:d}/{:d}\".format(count,len(dataset)),end=\"\\r\")\n",
    "        count += 1\n",
    "        inputs,labels = data\n",
    "        if use_gpu:\n",
    "            inputs , labels = Variable(inputs.cuda()),Variable(labels.cuda())\n",
    "        else:\n",
    "            inputs , labels = Variable(inputs),Variable(labels)\n",
    "        \n",
    "        x = model_vgg.features(inputs)\n",
    "        conv_features.extend(x.data.cpu().numpy())\n",
    "        labels_list.extend(labels.data.cpu().numpy())\n",
    "    conv_features = np.concatenate([[feat] for feat in conv_features])\n",
    "    return (conv_features,labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582/2125\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 6 bytes but only got 0. Skipping tag 271\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 7 bytes but only got 0. Skipping tag 272\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 282\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 8 bytes but only got 0. Skipping tag 283\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:763: UserWarning: Possibly corrupt EXIF data.  Expecting to read 20 bytes but only got 0. Skipping tag 306\n",
      "  \" Skipping tag %s\" % (size, len(data), tag))\n",
      "/home/foodlovers/miniconda3/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:780: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19min, sys: 9min 45s, total: 28min 46s\n",
      "Wall time: 28min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_train,labels_train = preconvfeat(dset_loaders['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 59s, sys: 3min 4s, total: 9min 4s\n",
      "Wall time: 9min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "conv_feat_val,labels_val = preconvfeat(dset_loaders['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conv_feat_val' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-65878faa58e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/foodlovers/vgg16/conv_feat_train.bc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_feat_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/foodlovers/vgg16/labels_train.bc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/foodlovers/vgg16/conv_feat_val.bc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconv_feat_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0msave_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/home/foodlovers/vgg16/labels_val.bc'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conv_feat_val' is not defined"
     ]
    }
   ],
   "source": [
    "save_array('/home/foodlovers/vgg16/conv_feat_train.bc',conv_feat_train)\n",
    "save_array('/home/foodlovers/vgg16/labels_train.bc',labels_train)\n",
    "save_array('/home/foodlovers/vgg16/conv_feat_val.bc',conv_feat_val)\n",
    "save_array('/home/foodlovers/vgg16/labels_val.bc',labels_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_feat_train = load_array('/home/foodlovers/vgg16/conv_feat_train.bc')\n",
    "labels_train = load_array('/home/foodlovers/vgg16/labels_train.bc')\n",
    "conv_feat_val = load_array('/home/foodlovers/vgg16/conv_feat_val.bc')\n",
    "labels_val = load_array('/home/foodlovers/vgg16/labels_val.bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(67988, 512, 7, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsets['train'].imgs) == len(conv_feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels_train[:10])\n",
    "print([x[1] for x in dsets['train'].imgs[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True !\n"
     ]
    }
   ],
   "source": [
    "for i,label in enumerate(labels_train) :\n",
    "    if label != dsets['train'].imgs[i][1] :\n",
    "        print(\"Wrong !!!\")\n",
    "for i,label in enumerate(labels_val) :\n",
    "    if label != dsets['test'].imgs[i][1] :\n",
    "        print(\"Wrong !!!\")\n",
    "print(\"True !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load corresponding text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed textes in Food_Text_Classifier.ipynb\n",
    "text_dir = '/home/foodlovers/FoodVisor/data/processed_texts_txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apple_pie', 'apple_pie_100.jpg']\n",
      "apple_pie/apple_pie_100.txt\n",
      "/home/foodlovers/FoodVisor/data/processed_texts_txt/apple_pie/apple_pie_100.txt\n",
      "My account My newslett My groceri list My save custom care log My box submit log subscrib digit edit give gift cookbook subscrib best BY cours appet breakfast dessert dinner side cours BY beef chicken strawberri tomato watermelon BY style grill ahead potluck quick slow cooker style healthi budget video partner advanc see submit contest save best deal subscrib today holiday holiday juli th labor day celebr summer entertain birthday holiday celebr fourth OF juli flagshap grill classic american pie red white blue dessert juli th commun commun favorit forum group commun facebook pinterest tumblr google twitter popular pin check pinterest follow school school Us find show school meet staff faq school find show attend show fun uniqu night learn skill memori 'll last lifetim find show cookbook across america discov countri best flavor shop cookbook across america ecookbook cookbook subscrib tri america 'S magazin real best famili favorit everi issu tast save best deal subscrib today subscrib newslett issu digit edit give gift custom care subscrib renew glaze appl pie squar glaze appl pie squar photo tast glaze appl pie squar read review realli good chang appl pie sinc glaze littl bit sweeter dough firm enough eat hand best appl season dian turner brunswick ohio inbox day free day newslett inbox day free day newslett total prep hour bake min cool box print friend total prep hour bake min cool allpurpos flour teaspoon salt cold butter cube egg separ tablespoon milk crush cornflak thinli slice peel tart appl medium plu tablespoon sugar divid teaspoon ground cinnamon divid teaspoon ground nutmeg glaze confection sugar teaspoon vanilla extract tablespoon milk My save groceri list nutrit fact squar equal calori fat satur fat mg cholesterol mg sodium carbohydr fiber protein direct larg bowl combin flour salt cut butter mixtur resembl coars crumb measur combin egg yolk enough milk measur gradual flour mixtur toss fork dough form ball preheat oven divid dough half roll portion thin xin rectangl transfer bottom ungreas xx bake pan sprinkl cornflak larg bowl combin appl sugar teaspoon cinnamon nutmeg toss coat spoon crust roll remain dough thin xin rectangl place appl fill beat egg white brush pastri combin remain sugar cinnamon sprinkl bake golden brown glaze combin confection sugar vanilla enough milk achiev drizzl consist drizzl warm pastri cool complet wire rack cut squar yield dozen origin publish glaze appl pie squar tast februarymarch nutrit fact squar equal calori fat satur fat mg cholesterol mg sodium carbohydr fiber protein print box friend review glaze appl pie squar averag rate rate distribut star star star star star MY review pleas log join rate review log review click star rate ani chang rate review appear origin review submit review edit review updat review cancel sort By newest first oldest first highest rate lowest rate MY review review may yum MY review yahoocom review nov made sever first exactli written except pan My husband sinc made less sugar still veri veri good MY review pooki mama review nov mani pick 'm glad fresh pick appl omit cornflak extra flour sweet rich flavor held veri nice bar got rave review gone quickli crust tender flakey wow MY review review sep got exact aunt year ago except call danish appl bar 're delici MY review review sep year onli coupl tbsp sugar becaus appl tart usual cinnamon tast instead vanilla glaze real almond realli someth alway cornflak crispix special etc sometim sprinkl bottom mix appl cinnamon mix brought work never ani left coffe break staff would sneak would sure view review similar sausag appl squar sour cream appl squar appl snack squar appl walnut squar appl harvest squar mock appl pie squar appl pastri squar applesauc gelatin squar pear dessert squar appl walnut bar cognac date squar creami cashew browni collect tast magazin appl dessert appl pie appl pie crust appl pie appl pie fresh appl appl bar comfort dessert comfort dessert father day fruit pie homemad pie crust low fat dessert low fat pie bake pie crust pie crust butter pie potluck dessert potluck sweet finger tast magazin dessert tast magazin advertis us advertis sign Up newslett popular month deliv inbox sign UP invalid contest promot follow Us advertis us advertis advertis us advertis print ipad kindl nook holiday school commun cookbook magazin Us contest rss magazin custom servic Us log log help press room advertis site map term condit privaci sign UP newslett sign UP invalid follow US Us contest rss magazin custom servic Us log log help privaci press room advertis site map term condit rda enthusiast brand llc select usernam field requir usernam usernam incorrect pleas select usernam appear public area site commun request usernam enter valid usernam usernam alreadi exist usernam contain space special charact password pleas enter password forgot password rememb Me log cancel log cancel join member whi save favorit free person box thought made sign free newslett join\n"
     ]
    }
   ],
   "source": [
    "file_path = dsets['train'].imgs[1][0]\n",
    "print(file_path.split(\"/\")[-2:])\n",
    "print(\"/\".join(file_path.split(\"/\")[-2:])[:-3]+'txt')\n",
    "path_text = text_dir+'/'+\"/\".join(file_path.split(\"/\")[-2:])[:-3]+'txt'\n",
    "print(path_text)\n",
    "text_file = open(path_text, \"r\")\n",
    "text = text_file.read()\n",
    "text_file.close()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3908  images don't have text file\n"
     ]
    }
   ],
   "source": [
    "text_train = []\n",
    "text_val = []\n",
    "# a lot of file don't contain any text\n",
    "valid_conv_feat_train = []\n",
    "valid_labels_train = []\n",
    "valid_conv_feat_val = []\n",
    "valid_labels_val = []\n",
    "\n",
    "unvalid_count = 0\n",
    "for i in range(len(conv_feat_train)) :\n",
    "    try :\n",
    "        file_path = dsets['train'].imgs[i][0]\n",
    "        path_text = text_dir+'/'+\"/\".join(file_path.split(\"/\")[-2:])[:-3]+'txt'\n",
    "        text_file = open(path_text, \"r\")\n",
    "        text = text_file.read()\n",
    "        text_file.close()\n",
    "        text_train.append(text)\n",
    "        valid_conv_feat_train.append(conv_feat_train[i])\n",
    "        valid_labels_train.append(labels_train[i])\n",
    "    except FileNotFoundError :\n",
    "        # print(file_path)\n",
    "        unvalid_count += 1\n",
    "    \n",
    "for i in range(len(conv_feat_val)) :\n",
    "    try :\n",
    "        file_path = dsets['test'].imgs[i][0]\n",
    "        path_text = text_dir+'/'+\"/\".join(file_path.split(\"/\")[-2:])[:-3]+'txt'\n",
    "        text_file = open(path_text, \"r\")\n",
    "        text = text_file.read()\n",
    "        text_file.close()\n",
    "        text_val.append(text)\n",
    "        valid_conv_feat_val.append(conv_feat_val[i])\n",
    "        valid_labels_val.append(labels_val[i])\n",
    "    except FileNotFoundError :\n",
    "        # print(file_path)\n",
    "        unvalid_count += 1\n",
    "        \n",
    "print(unvalid_count,\" images don't have text file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 65101 test: 21695\n"
     ]
    }
   ],
   "source": [
    "print(\"train:\",len(text_train),\"test:\",len(text_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform text file into TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 57 s, sys: 319 ms, total: 57.3 s\n",
      "Wall time: 56.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(binary=True)\n",
    "text_feat_train = tfidf.fit_transform(text_train)\n",
    "#.astype('float16')\n",
    "text_feat_val = tfidf.transform(text_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65101, 60033)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_feat_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_conv_feat_train = np.asarray(valid_conv_feat_train).reshape(len(valid_conv_feat_train),-1)\n",
    "valid_conv_feat_val = np.asarray(valid_conv_feat_val).reshape(len(valid_conv_feat_val),-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test image features with linearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 36s, sys: 3.93 s, total: 21min 40s\n",
      "Wall time: 21min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clf = LinearSVC()\n",
    "clf.fit(valid_conv_feat_train, valid_labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.3752477529384651\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred = clf.predict(valid_conv_feat_val)\n",
    "accuracy = accuracy_score(valid_labels_val, y_pred)\n",
    "print(\"Accuracy : \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build my model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count les nombres de parametres ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text features shape: (65101, 60033) Image features shape: (65101, 25088)\n"
     ]
    }
   ],
   "source": [
    "print(\"Text features shape:\",text_feat_train.shape,\"Image features shape:\",valid_conv_feat_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_gpu = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train textual features with a sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myNet, self).__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(60033, 1024),\n",
    "            nn.Linear(1024, 101)\n",
    "        ) \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = myNet()\n",
    "\n",
    "if use_gpu:\n",
    "    net1 = net1.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen_1(data,labels,batch_size=64,shuffle=True):\n",
    "    labels = np.array(labels)\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(len(labels))\n",
    "        data = data[index]\n",
    "        labels = labels[index]\n",
    "    for idx in range(0,len(labels),batch_size):\n",
    "        if type(data).__module__ == 'numpy' :\n",
    "            yield(data[idx:idx+batch_size],labels[idx:idx+batch_size],\n",
    "             int(len(labels) / batch_size) + (len(labels) % batch_size > 0))\n",
    "        else :\n",
    "            yield(data[idx:idx+batch_size].toarray(),labels[idx:idx+batch_size],\n",
    "             int(len(labels) / batch_size) + (len(labels) % batch_size > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_1(model, criterion, batch_size = 64,\n",
    "                 train_data = None, train_labels = None,\n",
    "                 test_data = None, test_labels = None,\n",
    "                  optimizer = None,\n",
    "                 epochs = 1,train = True, validate = False,\n",
    "                shuffle = True) :\n",
    "    \n",
    "    if train == True :\n",
    "        loss_history = []\n",
    "        acc_history = []\n",
    "        val_loss_history = []\n",
    "        val_acc_history = []\n",
    "        \n",
    "    for epoch in range(epochs) :\n",
    "        if train == True :\n",
    "            #=========================TRAINING=================================#\n",
    "            start_time_epoch = time.time()\n",
    "            \n",
    "            model.train()\n",
    "    \n",
    "            print(\"Epoch:\", epoch,\"/\",epochs-1,\"===============================================\")\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            batches = data_gen_1(data=train_data,labels=train_labels,shuffle=shuffle)\n",
    "            \n",
    "            #batch_num = len(list(batches))\n",
    "\n",
    "            for i,data in enumerate(batches) :\n",
    "                start_time = time.time()\n",
    "        \n",
    "                inputs,classes,batch_num = data\n",
    "\n",
    "                if  isinstance(inputs, (list, np.ndarray)) :\n",
    "                    inputs , classes = torch.from_numpy(inputs), torch.from_numpy(classes)\n",
    "                    \n",
    "                inputs = inputs.float()\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs , classes = inputs.cuda(), classes.cuda()\n",
    "\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                    \n",
    "                # calulate outputs and losses\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs,classes)       \n",
    "\n",
    "                # autograd\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                batch_loss = loss.data.item()\n",
    "                _,preds = torch.max(outputs.data,1)\n",
    "                batch_corrects = torch.sum(preds == classes.data)\n",
    "                \n",
    "                running_loss += batch_loss\n",
    "                running_corrects += batch_corrects\n",
    "\n",
    "                print('Batch {:d}/{:d} - Loss: {:.4f} Acc: {:.4f} - Time : {:.2f}s'.format(i+1,batch_num,\n",
    "                             batch_loss/len(classes), float(batch_corrects)/len(classes), time.time() - start_time),end='\\r')\n",
    "\n",
    "            epoch_loss = running_loss / len(train_labels)\n",
    "            epoch_acc = running_corrects.data.item() / len(train_labels)\n",
    "            #\n",
    "            \n",
    "            loss_history.append(epoch_loss)\n",
    "            acc_history.append(epoch_acc)\n",
    "            \n",
    "            print('Epoch {:d} completed in {:.2f} seconds ! Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch , time.time() - start_time_epoch, epoch_loss, epoch_acc))\n",
    "            \n",
    "        if validate == True :\n",
    "            #=========================VALIDATING=================================#\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0.0\n",
    "            \n",
    "            batches = data_gen_1(data=test_data,labels=test_labels,shuffle=shuffle)\n",
    "            \n",
    "            #batch_num = len(list(batches))\n",
    "\n",
    "            for i,data in enumerate(batches) :\n",
    "                start_time = time.time()\n",
    "                \n",
    "                inputs,classes,batch_num = data\n",
    "                \n",
    "                if  isinstance(inputs, (list, np.ndarray)) :\n",
    "                    inputs , classes = torch.from_numpy(inputs), torch.from_numpy(classes)\n",
    "                    \n",
    "                inputs = inputs.float()\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs , classes = inputs.cuda(), classes.cuda()\n",
    "                    \n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs,classes)        \n",
    "                _,preds = torch.max(outputs.data,1)\n",
    "\n",
    "                # statistics\n",
    "\n",
    "                val_loss += loss.data.item()\n",
    "                val_corrects += torch.sum(preds == classes.data)\n",
    "                \n",
    "                print('Validating batch {:d}/{:d} - {:.2f}s ...'.format(i+1,batch_num\n",
    "                                                                , time.time() - start_time), end=\"\\r\")\n",
    "\n",
    "            val_epoch_loss = val_loss / len(test_labels)\n",
    "            val_epoch_acc = val_corrects.data.item() / len(test_labels)\n",
    "            # \n",
    "\n",
    "            print('Val Loss: {:.4f} Val Acc: {:.4f}'.format(\n",
    "                             val_epoch_loss,val_epoch_acc))\n",
    "            \n",
    "            if train == False :\n",
    "                return\n",
    "            else :\n",
    "                val_loss_history.append(val_epoch_loss)\n",
    "                val_acc_history.append(val_epoch_acc)\n",
    "    \n",
    "    if train == False :\n",
    "        return 'On fait rien!'\n",
    "    elif validate == False :\n",
    "        return loss_history, acc_history\n",
    "    else :\n",
    "        return loss_history, acc_history,val_loss_history,val_acc_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "# optimizer = torch.optim.SGD(net1.parameters(),lr = lr,momentum = 0.9)\n",
    "optimizer = torch.optim.Adam(net1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 4 ===============================================\n",
      "Epoch 0 completed in 69.15 seconds ! Loss: 0.0250 Acc: 0.6792\n",
      "Val Loss: 0.0120 Val Acc: 0.8287 ...\n",
      "Epoch: 1 / 4 ===============================================\n",
      "Epoch 1 completed in 69.18 seconds ! Loss: 0.0053 Acc: 0.9277\n",
      "Val Loss: 0.0116 Val Acc: 0.8341 ...\n",
      "Epoch: 2 / 4 ===============================================\n",
      "Epoch 2 completed in 69.30 seconds ! Loss: 0.0037 Acc: 0.9527\n",
      "Val Loss: 0.0116 Val Acc: 0.8338 ...\n",
      "Epoch: 3 / 4 ===============================================\n",
      "Epoch 3 completed in 69.25 seconds ! Loss: 0.0033 Acc: 0.9590\n",
      "Val Loss: 0.0116 Val Acc: 0.8364 ...\n",
      "Epoch: 4 / 4 ===============================================\n",
      "Epoch 4 completed in 69.18 seconds ! Loss: 0.0031 Acc: 0.9626\n",
      "Val Loss: 0.0116 Val Acc: 0.8372 ...\n",
      "DONE !\n",
      "CPU times: user 5min 5s, sys: 1min 32s, total: 6min 38s\n",
      "Wall time: 6min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train_model_1(net1,\n",
    "                train_data=text_feat_train ,train_labels=valid_labels_train , \n",
    "                test_data = text_feat_val , test_labels = valid_labels_val ,\n",
    "                epochs=5, batch_size = 32,\n",
    "                optimizer=optimizer,criterion=criterion ,\n",
    "                train=True, validate = True,\n",
    "                shuffle=True )\n",
    "print(\"DONE !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0116 Val Acc: 0.8372 ...\n"
     ]
    }
   ],
   "source": [
    "history = train_model_1(net1,\n",
    "                train_data=text_feat_train ,train_labels=valid_labels_train , \n",
    "                test_data = text_feat_val , test_labels = valid_labels_val ,\n",
    "                epochs=10, batch_size = 32,\n",
    "                optimizer=optimizer,criterion=criterion ,\n",
    "                train=False, validate = True,\n",
    "                shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on Image features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not defined above\n",
    "model_vgg = models.vgg16(pretrained=True)\n",
    "model_vgg.classifier._modules['6'] = nn.Linear(4096, 101)\n",
    "if use_gpu:\n",
    "    model_vgg = model_vgg.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model_vgg.classifier.parameters(),lr = lr,momentum = 0.9)\n",
    "# optimizer = torch.optim.Adam(model_vgg.classifier.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "  (1): ReLU(inplace)\n",
      "  (2): Dropout(p=0.5)\n",
      "  (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "  (4): ReLU(inplace)\n",
      "  (5): Dropout(p=0.5)\n",
      "  (6): Linear(in_features=4096, out_features=101, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model_vgg.classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_vgg.classifier.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 4 ===============================================\n",
      "Epoch 0 completed in 64.01 seconds ! Loss: 0.0504 Acc: 0.2562\n",
      "Val Loss: 0.0413 Val Acc: 0.3900 ...\n",
      "Epoch: 1 / 4 ===============================================\n",
      "Epoch 1 completed in 112.47 seconds ! Loss: 0.0438 Acc: 0.3363\n",
      "Val Loss: 0.0408 Val Acc: 0.4047 ...\n",
      "Epoch: 2 / 4 ===============================================\n",
      "Epoch 2 completed in 116.81 seconds ! Loss: 0.0390 Acc: 0.4010\n",
      "Val Loss: 0.0406 Val Acc: 0.4126 ...\n",
      "Epoch: 3 / 4 ===============================================\n",
      "Epoch 3 completed in 116.54 seconds ! Loss: 0.0348 Acc: 0.4580\n",
      "Val Loss: 0.0396 Val Acc: 0.4289 ...\n",
      "Epoch: 4 / 4 ===============================================\n",
      "Epoch 4 completed in 73.34 seconds ! Loss: 0.0309 Acc: 0.5150\n",
      "Val Loss: 0.0394 Val Acc: 0.4374 ...\n",
      "CPU times: user 5min 43s, sys: 2min 55s, total: 8min 38s\n",
      "Wall time: 8min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "history = train_model_1(model_vgg.classifier,\n",
    "                train_data=valid_conv_feat_train  ,train_labels=valid_labels_train , \n",
    "                test_data = valid_conv_feat_val  , test_labels = valid_labels_val ,\n",
    "                epochs=5, batch_size = 32,\n",
    "                optimizer=optimizer,criterion=criterion ,\n",
    "                train=True, validate = True,\n",
    "                shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 4 ===============================================\n",
      "Epoch 0 completed in 112.31 seconds ! Loss: 0.0278 Acc: 0.5580\n",
      "Val Loss: 0.0405 Val Acc: 0.4250 ...\n",
      "Epoch: 1 / 4 ===============================================\n",
      "Epoch 1 completed in 105.36 seconds ! Loss: 0.0255 Acc: 0.5953\n",
      "Val Loss: 0.0407 Val Acc: 0.4287 ...\n",
      "Epoch: 2 / 4 ===============================================\n",
      "Batch 329/1018 - Loss: 0.0246 Acc: 0.5781 - Time : 0.11s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-716b2806c63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                 \u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                 shuffle=True )\n\u001b[0m",
      "\u001b[0;32m<ipython-input-34-80c116f28094>\u001b[0m in \u001b[0;36mtrain_model_1\u001b[0;34m(model, criterion, batch_size, train_data, train_labels, test_data, test_labels, optimizer, epochs, train, validate, shuffle)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mbatch_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model_1(model_vgg.classifier,\n",
    "                train_data=valid_conv_feat_train  ,train_labels=valid_labels_train , \n",
    "                test_data = valid_conv_feat_val  , test_labels = valid_labels_val ,\n",
    "                epochs=5, batch_size = 32,\n",
    "                optimizer=optimizer,criterion=criterion ,\n",
    "                train=True, validate = True,\n",
    "                shuffle=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0401 Val Acc: 0.4276 ...\n"
     ]
    }
   ],
   "source": [
    "train_model_1(model_vgg.classifier,\n",
    "                train_data=valid_conv_feat_train  ,train_labels=valid_labels_train , \n",
    "                test_data = valid_conv_feat_val  , test_labels = valid_labels_val ,\n",
    "                epochs=10, batch_size = 32,\n",
    "                optimizer=optimizer,criterion=criterion ,\n",
    "                train=False, validate = True,\n",
    "                shuffle=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myFusionNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myFusionNet, self).__init__()\n",
    "#         self.fc1 = nn.Sequential(\n",
    "#             nn.Linear(60033, 512),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(512, 128),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(128, 101),\n",
    "#         ) \n",
    "#         self.fc2 = nn.Sequential(\n",
    "#             nn.Linear(25088, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(0.3),\n",
    "#             nn.Linear(4096, 4096),\n",
    "#             nn.ReLU(True),\n",
    "#             nn.Dropout(0.5),\n",
    "#             nn.Linear(4096, 101),\n",
    "#         ) \n",
    "        self.ratio = torch.tensor(0.8, requires_grad=True, device=\"cuda\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x should have shape (?,60033+25088)\n",
    "        x1 = x[:,:60033]\n",
    "        x2 = x[:,-25088:]\n",
    "        #x1 = self.fc1(x1)\n",
    "        #x2 = self.fc2(x2)\n",
    "        x1 = net1(x1)\n",
    "        x2 = model_vgg.classifier(x2)\n",
    "        out = self.ratio*x1 + (1-self.ratio)*x2\n",
    "        # out = torch.cat((x1,x2),1)\n",
    "        # out = self.classifier(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "myFusionNet()\n"
     ]
    }
   ],
   "source": [
    "mynet = myFusionNet()\n",
    "print(mynet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_gpu:\n",
    "    mynet = mynet.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss & optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "lr = 0.01\n",
    "optimizer = torch.optim.SGD(list([mynet.ratio]),lr = lr,momentum = 0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define datagen + train_model for data fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_gen(data1,data2,labels,batch_size=32,shuffle=True):\n",
    "    \"\"\"\n",
    "    data1 expected to be text_feat of type csr_matrix\n",
    "    data2 expected to be conv_feat of type ndarray\n",
    "    \"\"\"\n",
    "    labels = np.array(labels)\n",
    "    if shuffle:\n",
    "        index = np.random.permutation(len(labels))\n",
    "        data1 = data1[index]\n",
    "        data2 = data2[index]\n",
    "        labels = labels[index]\n",
    "    for idx in range(0,len(labels),batch_size):\n",
    "        yield(np.concatenate((data1[idx:idx+batch_size].toarray(), data2[idx:idx+batch_size]), axis=1)\n",
    "              ,labels[idx:idx+batch_size],\n",
    "             int(len(labels) / batch_size) + (len(labels) % batch_size > 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_2(model, criterion,\n",
    "                 train_data1 = None,train_data2=None, train_labels = None,\n",
    "                 test_data1 = None,test_data2=None, test_labels = None,\n",
    "                  optimizer = None,\n",
    "                 epochs = 1,train = True, validate = False,\n",
    "                shuffle = True) :\n",
    "    \n",
    "    if train == True :\n",
    "        loss_history = []\n",
    "        acc_history = []\n",
    "        val_loss_history = []\n",
    "        val_acc_history = []\n",
    "        \n",
    "    for epoch in range(epochs) :\n",
    "        if train == True :\n",
    "            #=========================TRAINING=================================#\n",
    "            start_time_epoch = time.time()\n",
    "            \n",
    "            model.train()\n",
    "    \n",
    "            print(\"Epoch:\", epoch,\"/\",epochs-1,\"===============================================\")\n",
    "        \n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0.0\n",
    "            \n",
    "            batches = data_gen(data1=train_data1,data2=train_data2,labels=train_labels,shuffle=shuffle)\n",
    "            \n",
    "            #batch_num = len(list(batches))\n",
    "\n",
    "            for i,data in enumerate(batches) :\n",
    "                start_time = time.time()\n",
    "        \n",
    "                inputs,classes,batch_num = data\n",
    "\n",
    "                if  isinstance(inputs, (list, np.ndarray)) :\n",
    "                    inputs , classes = torch.from_numpy(inputs), torch.from_numpy(classes)\n",
    "                    \n",
    "                inputs = inputs.float()\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs , classes = inputs.cuda(), classes.cuda()\n",
    "\n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "                    \n",
    "                # calulate outputs and losses\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs,classes)       \n",
    "\n",
    "                # autograd\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                batch_loss = loss.data.item()\n",
    "                _,preds = torch.max(outputs.data,1)\n",
    "                batch_corrects = torch.sum(preds == classes.data)\n",
    "                \n",
    "                running_loss += batch_loss\n",
    "                running_corrects += batch_corrects\n",
    "\n",
    "                print('Batch {:d}/{:d} - Loss: {:.4f} Acc: {:.4f} - Time : {:.2f}s'.format(i+1,batch_num,\n",
    "                             batch_loss/len(classes), float(batch_corrects)/len(classes), time.time() - start_time),end='\\r')\n",
    "\n",
    "            epoch_loss = running_loss / len(train_labels)\n",
    "            epoch_acc = running_corrects.data.item() / len(train_labels)\n",
    "            #\n",
    "            \n",
    "            loss_history.append(epoch_loss)\n",
    "            acc_history.append(epoch_acc)\n",
    "            \n",
    "            print('Epoch {:d} completed in {:.2f} seconds ! Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                     epoch , time.time() - start_time_epoch, epoch_loss, epoch_acc))\n",
    "            \n",
    "        if validate == True :\n",
    "            #=========================VALIDATING=================================#\n",
    "            \n",
    "            model.eval()\n",
    "            \n",
    "            val_loss = 0.0\n",
    "            val_corrects = 0.0\n",
    "            \n",
    "            batches = data_gen(data1=test_data1,data2=test_data2,labels=test_labels,shuffle=shuffle)\n",
    "            \n",
    "            #batch_num = len(list(batches))\n",
    "\n",
    "            for i,data in enumerate(batches) :\n",
    "                start_time = time.time()\n",
    "                \n",
    "                inputs,classes,batch_num = data\n",
    "                \n",
    "                if  isinstance(inputs, (list, np.ndarray)) :\n",
    "                    inputs , classes = torch.from_numpy(inputs), torch.from_numpy(classes)\n",
    "                    \n",
    "                inputs = inputs.float()\n",
    "\n",
    "                if use_gpu:\n",
    "                    inputs , classes = inputs.cuda(), classes.cuda()\n",
    "                    \n",
    "                inputs = inputs.view(inputs.size(0), -1)\n",
    "\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs,classes)        \n",
    "                _,preds = torch.max(outputs.data,1)\n",
    "\n",
    "                # statistics\n",
    "\n",
    "                val_loss += loss.data.item()\n",
    "                val_corrects += torch.sum(preds == classes.data)\n",
    "                \n",
    "                print('Validating batch {:d}/{:d} - {:.2f}s ...'.format(i+1,batch_num\n",
    "                                                                , time.time() - start_time), end=\"\\r\")\n",
    "\n",
    "            val_epoch_loss = val_loss / len(test_labels)\n",
    "            val_epoch_acc = val_corrects.data.item() / len(test_labels)\n",
    "            # \n",
    "\n",
    "            print('Val Loss: {:.4f} Val Acc: {:.4f}'.format(\n",
    "                             val_epoch_loss,val_epoch_acc))\n",
    "            \n",
    "            if train == False :\n",
    "                return\n",
    "            else :\n",
    "                val_loss_history.append(val_epoch_loss)\n",
    "                val_acc_history.append(val_epoch_acc)\n",
    "    \n",
    "    if train == False :\n",
    "        return 'On fait rien!'\n",
    "    elif validate == False :\n",
    "        return loss_history, acc_history\n",
    "    else :\n",
    "        return loss_history, acc_history,val_loss_history,val_acc_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 / 4 ===============================================\n",
      "Epoch 0 completed in 184.35 seconds ! Loss: 0.0025 Acc: 0.9882\n",
      "Val Loss: 0.0164 Val Acc: 0.8817 ...\n",
      "Epoch: 1 / 4 ===============================================\n",
      "Epoch 1 completed in 182.49 seconds ! Loss: 0.0025 Acc: 0.9884\n",
      "Val Loss: 0.0164 Val Acc: 0.8834 ...\n",
      "Epoch: 2 / 4 ===============================================\n",
      "Epoch 2 completed in 182.68 seconds ! Loss: 0.0025 Acc: 0.9881\n",
      "Val Loss: 0.0164 Val Acc: 0.8836 ...\n",
      "Epoch: 3 / 4 ===============================================\n",
      "Batch 1161/2035 - Loss: 0.0010 Acc: 1.0000 - Time : 0.06s\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-80f3aa53755a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m                   \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m                 shuffle = True)\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-2335154851e5>\u001b[0m in \u001b[0;36mtrain_model_2\u001b[0;34m(model, criterion, train_data1, train_data2, train_labels, test_data1, test_data2, test_labels, optimizer, epochs, train, validate, shuffle)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0;31m# statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0mbatch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m                 \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mbatch_corrects\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = train_model_2(model=mynet,criterion=criterion,\n",
    "              train_data1 = text_feat_train,train_data2=valid_conv_feat_train, train_labels = valid_labels_train,\n",
    "                 test_data1 = text_feat_val,test_data2= valid_conv_feat_val, test_labels = valid_labels_val,\n",
    "                  optimizer = optimizer,\n",
    "                 epochs = 5,train = True, validate = True,\n",
    "                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.5331, device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mynet.ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val Loss: 0.0170 Val Acc: 0.8836 ...\n"
     ]
    }
   ],
   "source": [
    "history = train_model_2(model=mynet,criterion=criterion,\n",
    "              train_data1 = text_feat_train,train_data2=valid_conv_feat_train, train_labels = valid_labels_train,\n",
    "                 test_data1 = text_feat_val,test_data2= valid_conv_feat_val, test_labels = valid_labels_val,\n",
    "                  optimizer = optimizer,\n",
    "                 epochs = 10,train = False, validate = True,\n",
    "                shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
